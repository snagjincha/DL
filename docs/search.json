[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/DL_Summary1.html",
    "href": "posts/DL_Summary1.html",
    "title": "Deep Learning 1",
    "section": "",
    "text": "1. Imports\n\nimport torch\nimport matplotlib.pyplot as plt \n\n\n\n2. RoadMap\n회귀분석 -&gt; 로지스틱 -&gt; 심층신경망(DNN) -&gt; 합성곱신경망(CNN)\n\n\n3. 회귀분석\n- 목적은 아래와 같이 데이터들에 잘 맞는 회귀선을 찾는 것\n\ntorch.manual_seed(21345)\nones= torch.ones(100).reshape(-1,1)\nx,_ = torch.randn(100).sort()\nx = x.reshape(-1,1)\nX = torch.concat([ones,x],axis=-1)\nW = torch.tensor([[2.5],[4]])\nϵ = torch.randn(100).reshape(-1,1)*0.5\ny = X@W + ϵ\n\n\nplt.plot(x,y,'o')\nplt.plot(x,2.5+4*x,'--')\n\n\n\n\n\n\n\n\n- 회귀모형에서 학습이란 위의 그림처럼 주황색 점선을 더 정확하게 추정하는 것\n\n\n4. 학습\n임의의 W값을 생각하자 그 다음 더 좋은 W값을 찾아서 업데이트 하면 되지 않을까?\n- Step1 Data\n데이터를 torch.tensor의 2차원 배열로 바꿔준다 .reshape(-1,1)을 사용 &lt;- 행렬계산을 해야하기에 2차원배열로 바꾸는 것\n- Step2 Update\n업데이트를 할 건데 뭘 어떻게 좋게 만들 것인지 기준을 잡아야한다. -&gt; Loss!(SSE)\n회귀직선이 정확할 수록 Loss가 작다.\n그렇다면 Loss값을 가장 작게 하는 W를 어떻게 찾을까?\nStep2-1 update의 정도를 파악하고 수정하는 과정\n\n임의의 점 \\(\\hat{w}\\) 를 찍는다.\n2.loss(W)의 기울기를 계산\n\\(\\hat{w}\\) - \\(\\alpha\\) \\(\\frac{d}{dW}loss(W)\\)\n\nStep2-2 \\(\\hat{w}\\) 수정\nWbefore = What.data\nWafter = What.data - \\(\\alpha\\) * What.grad\n- Step3 미분\nloss.backward()를 사용하면 What.grad()에 값이 생긴다. 곧 미분값\n- Step4 iteration\nfor문을 사용하여 반복학습 해준다\n\n\n각 Step의 변형\n- Step2의 변형\nMSELoss()를 이용한다.\n- Step1의 변형\nnet오브젝트를 이용하여 원활한 학습을 위한 데이터 정리를 해준다.\n- Step4의 변형\noptimizer 오브젝트를 이용하여 학습을 진행한다.\n\ntemp = [-2.4821, -2.3621, -1.9973, -1.6239, -1.4792, -1.4635, -1.4509, -1.4435,\n        -1.3722, -1.3079, -1.1904, -1.1092, -1.1054, -1.0875, -0.9469, -0.9319,\n        -0.8643, -0.7858, -0.7549, -0.7421, -0.6948, -0.6103, -0.5830, -0.5621,\n        -0.5506, -0.5058, -0.4806, -0.4738, -0.4710, -0.4676, -0.3874, -0.3719,\n        -0.3688, -0.3159, -0.2775, -0.2772, -0.2734, -0.2721, -0.2668, -0.2155,\n        -0.2000, -0.1816, -0.1708, -0.1565, -0.1448, -0.1361, -0.1057, -0.0603,\n        -0.0559, -0.0214,  0.0655,  0.0684,  0.1195,  0.1420,  0.1521,  0.1568,\n         0.2646,  0.2656,  0.3157,  0.3220,  0.3461,  0.3984,  0.4190,  0.5443,\n         0.5579,  0.5913,  0.6148,  0.6469,  0.6469,  0.6523,  0.6674,  0.7059,\n         0.7141,  0.7822,  0.8154,  0.8668,  0.9291,  0.9804,  0.9853,  0.9941,\n         1.0376,  1.0393,  1.0697,  1.1024,  1.1126,  1.1532,  1.2289,  1.3403,\n         1.3494,  1.4279,  1.4994,  1.5031,  1.5437,  1.6789,  2.0832,  2.2444,\n         2.3935,  2.6056,  2.6057,  2.6632]\nsales= [-8.5420, -6.5767, -5.9496, -4.4794, -4.2516, -3.1326, -4.0239, -4.1862,\n        -3.3403, -2.2027, -2.0262, -2.5619, -1.3353, -2.0466, -0.4664, -1.3513,\n        -1.6472, -0.1089, -0.3071, -0.6299, -0.0438,  0.4163,  0.4166, -0.0943,\n         0.2662,  0.4591,  0.8905,  0.8998,  0.6314,  1.3845,  0.8085,  1.2594,\n         1.1211,  1.9232,  1.0619,  1.3552,  2.1161,  1.1437,  1.6245,  1.7639,\n         1.6022,  1.7465,  0.9830,  1.7824,  2.1116,  2.8621,  2.1165,  1.5226,\n         2.5572,  2.8361,  3.3956,  2.0679,  2.8140,  3.4852,  3.6059,  2.5966,\n         2.8854,  3.9173,  3.6527,  4.1029,  4.3125,  3.4026,  3.2180,  4.5686,\n         4.3772,  4.3075,  4.4895,  4.4827,  5.3170,  5.4987,  5.4632,  6.0328,\n         5.2842,  5.0539,  5.4538,  6.0337,  5.7250,  5.7587,  6.2020,  6.5992,\n         6.4621,  6.5140,  6.6846,  7.3497,  8.0909,  7.0794,  6.8667,  7.4229,\n         7.2544,  7.1967,  9.5006,  9.0339,  7.4887,  9.0759, 11.0946, 10.3260,\n        12.2665, 13.0983, 12.5468, 13.8340]\nx = torch.tensor(temp).reshape(-1,1)\nones = torch.ones(100).reshape(-1,1)\nX = torch.concat([ones,x],axis=1)\ny = torch.tensor(sales).reshape(-1,1)\n\nnet = torch.nn.Linear(\n    in_features=2,\n    out_features=1,\n    bias=False\n)\nnet.weight.data = torch.tensor([[-5.0,  10.0]])\n\nloss_fn = torch.nn.MSELoss()\n\noptimizr = torch.optim.SGD(net.parameters(),lr=0.1)\nfor epoc in range(30):\n    # step1: yhat \n    yhat = net(X)\n    # step2: loss\n    loss = loss_fn(yhat,y)\n    # step3: 미분\n    loss.backward()\n    # step4: update\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o')\nplt.plot(x,yhat.data,'--')\nplt.title(f'net.weight={net.weight.data.reshape(-1)}');\n\n\n\n\n\n\n\n\n\n\n5. 로지스틱\n\nx = torch.tensor([-6,-5,-4,-3,-2,-1, 0, 1, 2, 3, 4, 5, 6.0]).reshape(-1,1)\ny = torch.tensor([ 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1]).reshape(-1,1)\nplt.plot(x,y,'o')\n\n\n\n\n\n\n\n\n- 위와 같은 범주형 문제는 이전의 문제처럼 회귀문제로 생각하는 건 쉽지 않아 보인다. 로지스틱으로 해볼까?\n우리가 예측하고 싶은 건 underlying이다.\n\nx = torch.linspace(-1,1,2000).reshape(2000,1)\nw0 = -1\nw1 = 5\nu = w0 + x*w1 # 선형변환이네?\nv = torch.exp(u) / (1+torch.exp(u)) \ny = torch.bernoulli(v)\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1, out_features=1),\n    torch.nn.Sigmoid()\n)\nl1, a1 = net # 네트워크는 섭스크립터블 오브젝트이니까..\nl1.weight.data = torch.tensor([[-0.3]])\nl1.bias.data = torch.tensor([-0.8])\n#loss_fn = torch.nn.MSELoss() # -- 이 코드 일단 쓰지 않을게여\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25)\n#---#\nfor epoc in range(100):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = torch.mean((y-yhat)**2)\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.05)\nplt.plot(x,v,'--r')\nplt.plot(x,yhat.data,'--b')\nplt.title('after 100 epochs')\n\nText(0.5, 1.0, 'after 100 epochs')\n\n\n\n\n\n\n\n\n\n5000번 학습하면?\n\nx = torch.linspace(-1,1,2000).reshape(2000,1)\nw0 = -1\nw1 = 5\nu = w0 + x*w1 # 선형변환이네?\nv = torch.exp(u) / (1+torch.exp(u)) \ny = torch.bernoulli(v)\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1, out_features=1),\n    torch.nn.Sigmoid()\n)\nl1, a1 = net # 네트워크는 섭스크립터블 오브젝트이니까..\nl1.weight.data = torch.tensor([[-0.3]])\nl1.bias.data = torch.tensor([-0.8])\n#loss_fn = torch.nn.MSELoss() # -- 이 코드 일단 쓰지 않을게여\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25)\n#---#\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = torch.mean((y-yhat)**2)\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.05)\nplt.plot(x,v,'--r')\nplt.plot(x,yhat.data,'--b')\nplt.title('after 100 epochs')\n\nText(0.5, 1.0, 'after 100 epochs')\n\n\n\n\n\n\n\n\n\n그런데 우리가 초기값을 -0.8,-0.3 으로 운 좋게 잘 잡아서 적합이 이렇게 잘 된 거 아닐까?\n안 좋은 초기값을 잡으면 어떻게 될까? 그래도 적합 시켜줄까?\n\nimport torch\nimport matplotlib.pyplot as plt \nimport numpy as np\nimport pandas as pd\n\ndef plot_loss(loss_fn, ax=None, Wstar=[-1,5]):\n    w0hat,w1hat =torch.meshgrid(torch.arange(-10,3,0.1),torch.arange(-1,10,0.1),indexing='ij')\n    w0hat = w0hat.reshape(-1)\n    w1hat = w1hat.reshape(-1)\n    def l(w0hat,w1hat):\n        yhat = torch.exp(w0hat+w1hat*x)/(1+torch.exp(w0hat+w1hat*x))\n        return loss_fn(yhat,y) \n    loss = list(map(l,w0hat,w1hat))\n    #---#\n    if ax is None: \n        fig = plt.figure()\n        ax = fig.add_subplot(1,1,1,projection='3d')\n    ax.scatter(w0hat,w1hat,loss,s=0.001) \n    ax.scatter(w0hat[::20],w1hat[::20],loss[::20],s=0.1,color='C0') \n    w0star,w1star = np.array(Wstar).reshape(-1)\n    ax.scatter(w0star,w1star,l(w0star,w1star),s=200,marker='*',color='red',label=f\"W=[{w0star:.1f},{w1star:.1f}]\")\n    #---#\n    ax.elev = 15\n    ax.dist = -20\n    ax.azim = 75    \n    ax.legend()\n    ax.set_xlabel(r'$w_0$')  # x축 레이블 설정\n    ax.set_ylabel(r'$w_1$')  # y축 레이블 설정\n    ax.set_xticks([-10,-5,0])  # x축 틱 간격 설정\n    ax.set_yticks([-10,0,10])  # y축 틱 간격 설정\n\n\ndef learn_and_record(net, loss_fn, optimizr):\n    yhat_history = [] \n    loss_history = []\n    What_history = []\n    Whatgrad_history = []\n    What_history.append([net[0].bias.data.item(), net[0].weight.data.item()])\n    for epoc in range(100): \n        ## step1 \n        yhat = net(x)\n        ## step2 \n        loss = loss_fn(yhat,y)\n        ## step3\n        loss.backward() \n        ## step4 \n        optimizr.step()\n        ## record \n        if epoc % 5 ==0: \n            yhat_history.append(yhat.reshape(-1).data.tolist())\n            loss_history.append(loss.item())\n            What_history.append([net[0].bias.data.item(), net[0].weight.data.item()])\n            Whatgrad_history.append([net[0].bias.grad.item(), net[0].weight.grad.item()])\n        optimizr.zero_grad() \n        \n    return yhat_history, loss_history, What_history, Whatgrad_history\n\n\ndef show_animation(net, loss_fn, optimizr):\n    yhat_history,loss_history,What_history,Whatgrad_history = learn_and_record(net,loss_fn,optimizr)\n    \n    fig = plt.figure(figsize=(7.5,3.5))\n    ax1 = fig.add_subplot(1, 2, 1)\n    ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n    ## ax1: 왼쪽그림 \n    ax1.scatter(x,y,alpha=0.01)\n    ax1.scatter(x[0],y[0],color='C0',label=r\"observed data = $(x_i,y_i)$\")\n    ax1.plot(x,v,'--',label=r\"prob (true) = $(x_i,\\frac{exp(-1+5x_i)}{1+exp(-1+5x_i)})$\")    \n    line, = ax1.plot(x,yhat_history[0],'--',label=r\"prob (estimated) = $(x_i,\\hat{y}_i)$\") \n    ax1.legend()\n    ## ax2: 오른쪽그림 \n    plot_loss(loss_fn,ax2)\n    ax2.scatter(np.array(What_history)[0,0],np.array(What_history)[0,1],loss_history[0],color='blue',s=200,marker='*')    \n    def animate(epoc):\n        line.set_ydata(yhat_history[epoc])\n        w0hat = np.array(What_history)[epoc,0]\n        w1hat = np.array(What_history)[epoc,1]\n        w0hatgrad = np.array(Whatgrad_history)[epoc,0]\n        w1hatgrad = np.array(Whatgrad_history)[epoc,1]\n        ax2.scatter(w0hat,w1hat,loss_history[epoc],color='grey')\n        ax2.set_title(f\"What.grad=[{w0hatgrad:.4f},{w1hatgrad:.4f}]\",y=0.8)\n        fig.suptitle(f\"epoch={epoc*5} // What=[{w0hat:.2f},{w1hat:.2f}] // Loss={loss_fn.__class__.__name__} // Opt={optimizr.__class__.__name__}\")\n        return line\n    ani = animation.FuncAnimation(fig, animate, frames=20)    \n    plt.close()\n    return ani\n\n- 좋은 초기값\n\nfrom matplotlib import animation\nplt.rcParams[\"animation.html\"] = \"jshtml\"\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-0.8])\nnet[0].weight.data = torch.tensor([[-0.3]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- 최악의 초기값\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-10.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- 해결 접근법\n컴공 : 에폭을 늘릴까?\n산공 : 옵티마이저를 바꿀까?\n통계 : Loss를 바꿀까?\n\n\n손실함수의 개선\nLoss 중 BCELoss라는 것이 있는데 이것은 반복을 했을 때 원하는 만큼 움직이지 않는다면 가속도를 붙혀서 그 다음 반복시에는 더 많이 움직이게끔 방식이다.\n여기서 움직이게 한다는 건 Loss를 줄여서 적합을 시킨다는 의미이다.\n사용방법은 loss를 선언할 때 BCELoss() 라고 쓰면 된다\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1, out_features=1),\n    torch.nn.Sigmoid()\n)\nl1, a1 = net # 네트워크는 섭스크립터블 오브젝트이니까..\nl1.weight.data = torch.tensor([[-0.3]])\nl1.bias.data = torch.tensor([-0.8])\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25)\n#---#\nfor epoc in range(100):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y) # yhat부터 써야함\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.05)\nplt.plot(x,v,'--r')\nplt.plot(x,yhat.data,'--b')\nplt.title('after 100 epochs')\n\nText(0.5, 1.0, 'after 100 epochs')\n\n\n\n\n\n\n\n\n\n- MSELoss를 사용할 때보다 BCELoss를 사용했을 때 훨씬 더 적합이 되는 듯한 느낌이다.\n\nfig = plt.figure()\nax1 = fig.add_subplot(1,2,1,projection='3d')\nax2 = fig.add_subplot(1,2,2,projection='3d')\nplot_loss(torch.nn.MSELoss(),ax1)\nplot_loss(torch.nn.BCELoss(),ax2)\n\n\n\n\n\n\n\n\n뭔가 더 잘 떨어지게끔 오른쪽이 미끄럼틀같이 펴져있다.\n- MSELoss\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-0.8])\nnet[0].weight.data = torch.tensor([[-0.3]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- BCELoss\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-0.8])\nnet[0].weight.data = torch.tensor([[-0.3]])\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\n옵티마이저의 개선\n국민옵티마이저 Adam이 있다. 웬만하면 이거 쓰면 된다.\n- MSELoss + SGD\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-10.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.05) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n꿈쩍도 하지 않는 모습…\n- MSELoss + Adam\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-10.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n너무나도 뚝뚝 잘 내려온다\n- 그럼 BCELoss + Adam 쓰면 무적인가?\n\n\n6.로지스틱의 한계\n중소·지방 기업 “뽑아봤자 그만두니까”\n중소기업 관계자들은 고스펙 지원자를 꺼리는 이유로 높은 퇴직률을 꼽는다. 여건이 좋은 대기업으로 이직하거나 회사를 관두는 경우가 많다는 하소연이다. 고용정보원이 지난 3일 공개한 자료에 따르면 중소기업 청년취업자 가운데 49.5%가 2년 내에 회사를 그만두는 것으로 나타났다.\n중소 IT업체 관계자는 “기업 입장에서 가장 뼈아픈 게 신입사원이 그만둬서 새로 뽑는 일”이라며 “명문대 나온 스펙 좋은 지원자를 뽑아놔도 1년을 채우지 않고 그만두는 사원이 대부분이라 우리도 눈을 낮춰 사람을 뽑는다”고 말했다.\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/guebin/DL2024/main/posts/dnnex.csv\")\nx = torch.tensor(df.x).float().reshape(-1,1)\ny = torch.tensor(df.y).float().reshape(-1,1)\nprob = torch.tensor(df.prob).float().reshape(-1,1)\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(x[0],y[0],'o',label= r\"observed data = $(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,prob,'--b',label= r\"prob (true, unknown)\")\nplt.legend()\n\n\n\n\n\n\n\n\n- 이런 꺾인 선은 로지스틱으로 적합하기 힘들어…\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---# \nfor epoc in range(5000):\n    ## 1 \n    yhat = net(x)\n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(x[0],y[0],'o',label= r\"observed data = $(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,prob,'--b',label= r\"prob (true, unknown)\")\nplt.plot(x,net(x).data, '--', label= r\"prob (estimated) = $(x_i,\\hat{y}_i)$\")\nplt.legend()\n\n\n\n\n\n\n\n\n\n\n7.로지스틱의 한계 극복\nReLU : 음수인 것은 0으로 만들고 양수는 그대로 둔다. 그럼 그래프가 꺾인다.\n\ny = x*0 \ny[x&lt;0] = (9*x+4.5)[x&lt;0]\ny[x&gt;0] = (-4.5*x+4.5)[x&gt;0]\n\nplt.plot(y,'--')\n\n\n\n\n\n\n\n\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/guebin/DL2024/main/posts/dnnex.csv\")\nx = torch.tensor(df.x).float().reshape(-1,1)\ny = torch.tensor(df.y).float().reshape(-1,1)\nprob = torch.tensor(df.prob).float().reshape(-1,1)\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,2),\n    torch.nn.ReLU(),\n    torch.nn.Linear(2,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(3000):\n    ## \n    yhat = net(x)\n    ## \n    loss = loss_fn(yhat,y)\n    ## \n    loss.backward()\n    ## \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(x[0],y[0],'o',label= r\"observed data = $(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,prob,'--b',label= r\"prob (true, unknown)\")\nplt.plot(x,net(x).data,'--',label=\"prob (estimated) -- after 3000 epochs\")\nplt.legend()\n\n\n\n\n\n\n\n\n\nfor epoc in range(3000):\n    ## \n    yhat = net(x)\n    ## \n    loss = loss_fn(yhat,y)\n    ## \n    loss.backward()\n    ## \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(x[0],y[0],'o',label= r\"observed data = $(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,prob,'--b',label= r\"prob (true, unknown)\")\nplt.plot(x,net(x).data,'--',label=\"prob (estimated) -- after 6000 epochs\")\nplt.legend()\n\n\n\n\n\n\n\n\nReLU에 대해서는 깊게 알기보단 그래프를 꺾을 수 있다\n그 꺾는다는 의미는 표현력을 높인다고 생각하는 것이 좋다.\n로지스틱의 한계를 마주했을 때 그저 증가함수는 표현을 못 하는 그래프들이 있기때문에 문제였는데\n이제 ReLU를 이용해서 꺾인 선 그래프도 그릴 수 있게 되었고 그것으로 적합해서 맞춰나가면 해결할 수 있게 되었다.\n즉 그래프의 표현력이 늘었다. 그렇다면 모든 그래프도 적합할 수 있을 거 같은데?\n\ntorch.manual_seed(21345)\nx = torch.linspace(0,2,2000).reshape(-1,1)\neps = torch.randn(2000).reshape(-1,1)*0.05\nfx = torch.exp(-1*x)* torch.abs(torch.cos(3*x))*(torch.sin(3*x))\ny = fx + eps\n\nplt.plot(x,y,label=r\"observed data (with error): $(x_i,y_i)$\", alpha=0.2)\nplt.plot(x,fx,'--',color=\"C0\",label=r\"underlying (true, unknown): $e^{-x}|\\cos(3x)|\\sin(3x)$\")\nplt.legend()\n\n\n\n\n\n\n\n\n위의 문제는 로지스틱이 아니라 회귀선을 맞춰보는 느낌이 강하기에 MSELoss를 사용\n\n#torch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1024),\n    torch.nn.ReLU(),\n    torch.nn.Linear(1024,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#--#\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x)\n    ## 2\n    loss = loss_fn(yhat,y)\n    ## 3\n    loss.backward()\n    ## 4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,label=r\"observed data: $(x_i,y_i)$\", alpha=0.2)\nplt.plot(x,fx,'--',color=\"C0\",label=r\"underlying (true, unkown): $e^{-x}|\\cos(3x)|\\sin(3x)$\")\nplt.plot(x,yhat.data,'--',color=\"C1\",label=r\"underlying (esimated): $(x_i,\\hat{y}_i)$\")\nplt.legend()\n\n\n\n\n\n\n\n\n- 이렇게 복잡한 것도 잘 맞춰준다.\n\n\n8. 그럼 무적인가? (시벤코정리)\n치명적인 문제 : Overfiiting\n표현력은 무한하지만 오차까지 적합해버리는 문제가 있다\n이러한 문제를 해결하기 위해 드랍아웃이라는 기법이 존재함\n\nu = torch.randn(20).reshape(10,2)\nu\n\ntensor([[ 0.9303, -1.4108],\n        [ 0.1033,  0.3010],\n        [-0.3732,  2.3353],\n        [ 0.2152,  0.1908],\n        [-0.1696,  1.1762],\n        [-1.4862, -0.0343],\n        [-0.8385,  0.3719],\n        [ 0.9422,  0.9081],\n        [-1.3018, -0.7977],\n        [ 0.1008,  0.2014]])\n\n\n\nd = torch.nn.Dropout(0.9)\nd(u)\n\ntensor([[ 0.0000, -0.0000],\n        [ 1.0332,  0.0000],\n        [-0.0000,  0.0000],\n        [ 0.0000,  0.0000],\n        [-1.6961,  0.0000],\n        [-0.0000, -0.0000],\n        [-8.3853,  0.0000],\n        [ 0.0000,  0.0000],\n        [-0.0000, -0.0000],\n        [ 0.0000,  2.0141]])\n\n\n- 드랍아웃\n90%의 드랍아웃: 드랍아웃층의 입력 중 임의로 90%를 골라서 결과를 0으로 만든다. + 그리고 0이 되지않고 살아남은 값들은 10배 만큼 값이 커진다.\n의미: each iteration (each epoch x) 마다 학습에 참여하는 노드가 랜덤으로 결정됨.\n느낌: 모든 노드가 골고루 학습가능 + 한 두개의 특화된 능력치가 개발되기 보다 평균적인 능력치가 전반적으로 개선됨\n배깅과 랜덤포레스트의 느낌으로 오버피팅을 해결함"
  },
  {
    "objectID": "posts/DL_Summary2.html",
    "href": "posts/DL_Summary2.html",
    "title": "Deep Learning 2",
    "section": "",
    "text": "import torch\nimport matplotlib.pyplot as plt\nfrom fastai.data.all import *\nimport torchvision"
  },
  {
    "objectID": "posts/DL_Summary2.html#예시1-2층-히든레이어는-1층",
    "href": "posts/DL_Summary2.html#예시1-2층-히든레이어는-1층",
    "title": "Deep Learning 2",
    "section": "예시1 – 2층 (히든레이어는 1층)",
    "text": "예시1 – 2층 (히든레이어는 1층)\ntorch.nn.Sequential( torch.nn.Linear(??,??), ## &lt;– 학습해야할 가중치가 있는 층 torch.nn.ReLU(), torch.nn.Linear(??,??), ## &lt;– 학습해야할 가중치가 있는 층 )"
  },
  {
    "objectID": "posts/DL_Summary2.html#예시2-2층-히든레이어는-1층",
    "href": "posts/DL_Summary2.html#예시2-2층-히든레이어는-1층",
    "title": "Deep Learning 2",
    "section": "예시2 – 2층 (히든레이어는 1층)",
    "text": "예시2 – 2층 (히든레이어는 1층)\ntorch.nn.Sequential( torch.nn.Linear(??,??), ## &lt;– 학습해야할 가중치가 있는 층 torch.nn.ReLU(), torch.nn.Linear(??,??), ## &lt;– 학습해야할 가중치가 있는 층 torch.nn.Sigmoid(), )"
  },
  {
    "objectID": "posts/DL_Summary2.html#예시3-1층-히든레이어는-없음",
    "href": "posts/DL_Summary2.html#예시3-1층-히든레이어는-없음",
    "title": "Deep Learning 2",
    "section": "예시3 – 1층 (히든레이어는 없음!!)",
    "text": "예시3 – 1층 (히든레이어는 없음!!)\ntorch.nn.Sequential( torch.nn.Linear(??,??), ## &lt;– 학습해야할 가중치가 있는 층 )"
  },
  {
    "objectID": "posts/DL_Summary2.html#예시4-1층-히든레이어는-없음",
    "href": "posts/DL_Summary2.html#예시4-1층-히든레이어는-없음",
    "title": "Deep Learning 2",
    "section": "예시4 – 1층 (히든레이어는 없음!!)",
    "text": "예시4 – 1층 (히든레이어는 없음!!)\ntorch.nn.Sequential( torch.nn.Linear(??,??), ## &lt;– 학습해야할 가중치가 있는 층 torch.nn.Sigmoid() )"
  },
  {
    "objectID": "posts/DL_Summary2.html#예시5-3층-히든레이어는-2층",
    "href": "posts/DL_Summary2.html#예시5-3층-히든레이어는-2층",
    "title": "Deep Learning 2",
    "section": "예시5 – 3층 (히든레이어는 2층)",
    "text": "예시5 – 3층 (히든레이어는 2층)\ntorch.nn.Sequential( torch.nn.Linear(??,??), ## &lt;– 학습해야할 가중치가 있는 층 torch.nn.Sigmoid() torch.nn.Linear(??,??), ## &lt;– 학습해야할 가중치가 있는 층 torch.nn.Sigmoid() torch.nn.Linear(??,??), ## &lt;– 학습해야할 가중치가 있는 층\n)"
  },
  {
    "objectID": "posts/DL_Summary2.html#예시6-3층-히든레이어는-2층",
    "href": "posts/DL_Summary2.html#예시6-3층-히든레이어는-2층",
    "title": "Deep Learning 2",
    "section": "예시6 – 3층 (히든레이어는 2층)",
    "text": "예시6 – 3층 (히든레이어는 2층)\ntorch.nn.Sequential( torch.nn.Linear(??,??), ## &lt;– 학습해야할 가중치가 있는 층 torch.nn.ReLU() torch.nn.Dropout(??) torch.nn.Linear(??,??), ## &lt;– 학습해야할 가중치가 있는 층 torch.nn.ReLU() torch.nn.Dropout(??) torch.nn.Linear(??,??), ## &lt;– 학습해야할 가중치가 있는 층\ntorch.nn.Sigmoid() )"
  },
  {
    "objectID": "posts/DL_Summary2.html#a.-xy-데이터를-모두-굳이-gpu에-넘겨야-하는가",
    "href": "posts/DL_Summary2.html#a.-xy-데이터를-모두-굳이-gpu에-넘겨야-하는가",
    "title": "Deep Learning 2",
    "section": "A. X,y 데이터를 모두 굳이 GPU에 넘겨야 하는가?",
    "text": "A. X,y 데이터를 모두 굳이 GPU에 넘겨야 하는가?\n데이터셋을 짝홀로 나누어서 번갈아가면서 GPU에 올렸다 내렸다하면 안되나?\n- 아래의 알고리즘을 생각해보자.\n\n데이터를 반으로 나누고\n짝수 obs의 x,y,net의 모든 parameters을 GPU에 올린다\nyhat,loss,grad,update 수행\n홀수 obs의 x,y를 GPU메모리에서 내린다. 그리고 짝수 obs의 x,y를 GPU메모리에 올린다\nyhat,loss,grad,update 수행\n반복"
  },
  {
    "objectID": "posts/DL_Summary2.html#b.-미니배치-경사하강법",
    "href": "posts/DL_Summary2.html#b.-미니배치-경사하강법",
    "title": "Deep Learning 2",
    "section": "B. 미니배치 경사하강법",
    "text": "B. 미니배치 경사하강법\n그럼 홀수 짝수로 나누는 건 2로 나누는 건데 굳이 2로만 나누어야하나? 더 쪼갤 수 있지 않나?\n- gradient descent : 10개의 sample data가 있다고 할 때 모든 sample을 이용하여 slope계산\n- stochastic gradient descent with batch size = 1 : 10개의 smaple data를 하나씩으로 모두 쪼개서 slope계산\nstochastic gradient descent with batch size = 1의 경우는 epoc을 10번 하면 총 100번 epoc을 돌리는 것과 같다\n- stochastic gradient descent : m개의 sample을 이용하여 slope 계산\n그럼 stochastic gradient descent의 경우는 epoc을 10번 하면 총 40번 epoc을 돌리는 것과 같다."
  },
  {
    "objectID": "posts/DL_Summary2.html#c.-datasetds-dataloaderdl",
    "href": "posts/DL_Summary2.html#c.-datasetds-dataloaderdl",
    "title": "Deep Learning 2",
    "section": "C. Dataset(ds) , DataLoader(dl)",
    "text": "C. Dataset(ds) , DataLoader(dl)\nstochastic gradient descent를 수행하기 위해서 파이토치에서는 ds와 dl라는 오브젝트를 준비했다.\n\nx=torch.tensor(range(10)).float().reshape(-1,1)\ny=torch.tensor([1.0]*5+[0.0]*5).reshape(-1,1)\ntorch.concat([x,y],axis=1)\n\ntensor([[0., 1.],\n        [1., 1.],\n        [2., 1.],\n        [3., 1.],\n        [4., 1.],\n        [5., 0.],\n        [6., 0.],\n        [7., 0.],\n        [8., 0.],\n        [9., 0.]])\n\n\n\nds = torch.utils.data.TensorDataset(x,y)\n\ndir(ds)를 살펴보면 __getitem__이 있다 이러면 섭스크립터블하다는 것이다.\n\nds.tensors # 튜플 언패킹으로 뽑을 수 있을 거 같음\n\n(tensor([[0.],\n         [1.],\n         [2.],\n         [3.],\n         [4.],\n         [5.],\n         [6.],\n         [7.],\n         [8.],\n         [9.]]),\n tensor([[1.],\n         [1.],\n         [1.],\n         [1.],\n         [1.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [0.]]))\n\n\n\nds[0] , (x,y)[0]\n\n((tensor([0.]), tensor([1.])),\n tensor([[0.],\n         [1.],\n         [2.],\n         [3.],\n         [4.],\n         [5.],\n         [6.],\n         [7.],\n         [8.],\n         [9.]]))\n\n\n그런데 일반적인 튜플의 인덱싱과는 다르게 동작함\n\ndl=torch.utils.data.DataLoader(ds,batch_size=3)\ndl\n\n&lt;torch.utils.data.dataloader.DataLoader at 0x7fdf9fc2fec0&gt;\n\n\ndl : 섭스크립터블하지 않지만 이터러블 함 즉, for문을 사용할 수 있음\n\nfor xi,yi in dl:\n    print(xi,yi)\n\ntensor([[0.],\n        [1.],\n        [2.]]) tensor([[1.],\n        [1.],\n        [1.]])\ntensor([[3.],\n        [4.],\n        [5.]]) tensor([[1.],\n        [1.],\n        [0.]])\ntensor([[6.],\n        [7.],\n        [8.]]) tensor([[0.],\n        [0.],\n        [0.]])\ntensor([[9.]]) tensor([[0.]])\n\n\n10을 3으로 나누면 마지막에 하나 남는데 그건 어떻게 해? -&gt; 그냥 하나 남으면 그것만 계산한다"
  },
  {
    "objectID": "posts/DL_Summary2.html#d.-dsdl을-이용한-mnist구현",
    "href": "posts/DL_Summary2.html#d.-dsdl을-이용한-mnist구현",
    "title": "Deep Learning 2",
    "section": "D. ds,dl을 이용한 MNIST구현",
    "text": "D. ds,dl을 이용한 MNIST구현\n- 목표 : 확률적경사하강법과 그냥 경사하강법의 성능을 ’동일 반복횟수’로 비교해보자\n- 그냥 경사하강법 - mini-batch쓰지 않는 학습\n\npath = untar_data(URLs.MNIST)\nX0 = torch.stack(([torchvision.io.read_image(str(fname)) for fname in (path/'training/0').ls()]))\nX1 = torch.stack(([torchvision.io.read_image(str(fname)) for fname in (path/'training/1').ls()]))\nX = torch.concat([X0,X1],axis=0).reshape(-1,1*28*28)/255\ny = torch.tensor([0.0]*len(X0) + [1.0]*len(X1)).reshape(-1,1)\n\ntorch.manual_seed(21345)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1*28*28,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n)\n\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\nfor epoc in range(700):\n    yhat = net(X)\n    loss = loss_fn(yhat,y)\n    loss.backward()\n    optimizr.step()\n    optimizr.zero_grad()\n\n((yhat &gt; 0.5)*1.0 == y).float().mean()\n\ntensor(0.9998)\n\n\n\nplt.plot(y)\nplt.plot(yhat.data,'.')\n\n\n\n\n\n\n\n\n- ‘확률적’ 경사하강법 - mini-batch사용하는 학습\n\nds = torch.utils.data.TensorDataset(X,y)\ndl = torch.utils.data.DataLoader(ds,batch_size=2048)\n\npath = untar_data(URLs.MNIST)\nX0 = torch.stack(([torchvision.io.read_image(str(fname)) for fname in (path/'training/0').ls()]))\nX1 = torch.stack(([torchvision.io.read_image(str(fname)) for fname in (path/'training/1').ls()]))\nX = torch.concat([X0,X1],axis=0).reshape(-1,1*28*28)/255\ny = torch.tensor([0.0]*len(X0) + [1.0]*len(X1)).reshape(-1,1)\n\ntorch.manual_seed(21345)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1*28*28,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n)\n\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\nfor epoc in range(100):\n    for xi,yi in dl:\n        netout = net(xi)\n        loss = loss_fn(netout,yi)\n        loss.backward()\n        optimizr.step()\n        optimizr.zero_grad()\n\n((net(X) &gt; 0.5)*1.0 == y).float().mean()\n\ntensor(0.9992)\n\n\n\nplt.plot(y)\nplt.plot(yhat.data,'.')\n\n\n\n\n\n\n\n\n- GPU를 활용하는 ‘확률적’ 경사하강법 - 실제로는 이게 최종 알고리즘\n\nds = torch.utils.data.TensorDataset(X,y)\ndl = torch.utils.data.DataLoader(ds,batch_size=2048)\n\npath = untar_data(URLs.MNIST)\nX0 = torch.stack(([torchvision.io.read_image(str(fname)) for fname in (path/'training/0').ls()]))\nX1 = torch.stack(([torchvision.io.read_image(str(fname)) for fname in (path/'training/1').ls()]))\nX = torch.concat([X0,X1],axis=0).reshape(-1,1*28*28)/255\ny = torch.tensor([0.0]*len(X0) + [1.0]*len(X1)).reshape(-1,1)\n\ntorch.manual_seed(21345)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1*28*28,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n).to(\"cuda:0\")\n\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\nfor epoc in range(100):\n    for xi,yi in dl:\n        loss = loss_fn(net(xi.to(\"cuda:0\")),yi.to(\"cuda:0\"))\n        loss.backward()\n        optimizr.step()\n        optimizr.zero_grad()\n\nnet.to(\"cpu\")\n\n((net(X) &gt; 0.5)*1.0 == y).float().mean()\n\ntensor(0.9992)\n\n\n\nplt.plot(y)\nplt.plot(net(X).data.data,'.')"
  },
  {
    "objectID": "posts/DL_Summary2.html#a.-결론그냥-외워",
    "href": "posts/DL_Summary2.html#a.-결론그냥-외워",
    "title": "Deep Learning 2",
    "section": "A. 결론(그냥 외워)",
    "text": "A. 결론(그냥 외워)\n- 2개의 class를 구분하는 게 아니라 k개의 class를 구분해야 한다면?\ny의 형태 : (n,) vector + int형 // (n,k) one-hot encoded matrix + float형\n손실함수 : torch.nn.BCEWithLogitsLoss, -&gt; torch.nn.CrossEntropyLoss\n마지막층의 선형변환 : torch.nn.Linear(?,1) -&gt; torch.nn.Linear(?,k)\n마지막층의 활성화 : NONE -&gt; NONE (손실함수에 이미 포함되어있음)"
  },
  {
    "objectID": "posts/DL_Summary2.html#b.-실습-3개의-클래스를-구분",
    "href": "posts/DL_Summary2.html#b.-실습-3개의-클래스를-구분",
    "title": "Deep Learning 2",
    "section": "B. 실습 : 3개의 클래스를 구분",
    "text": "B. 실습 : 3개의 클래스를 구분\n- 1. 통계는 잘하는데 파이토치를 못하는 사람의 코드\n\n## Step1: 데이터준비 \npath = untar_data(URLs.MNIST)\nX0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/0').ls()])\nX1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/1').ls()])\nX2 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/2').ls()])\nX = torch.concat([X0,X1,X2]).reshape(-1,1*28*28)/255\ny = torch.nn.functional.one_hot(torch.tensor([0]*len(X0) + [1]*len(X1)+ [2]*len(X2))).float()\n## Step2: 학습가능한 오브젝트 생성\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,3),\n#    torch.nn.Softmax()\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n## Step3: 적합 \nfor epoc in range(100):\n    ## step1 \n    netout = net(X)\n    ## step2 \n    loss = loss_fn(netout,y)\n    ## step3 \n    loss.backward()\n    ## step4 \n    optimizr.step()\n    optimizr.zero_grad()\n    \n## Step4: 적합 (혹은 적합결과확인)\n(netout.argmax(axis=1) == y.argmax(axis=1)).float().mean()\n\ntensor(0.9827)\n\n\n- 2. 파이토치를 잘하는 사람의 코드\n\n## Step1: 데이터준비 \npath = untar_data(URLs.MNIST)\nX0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/0').ls()])\nX1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/1').ls()])\nX2 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/2').ls()])\nX = torch.concat([X0,X1,X2]).reshape(-1,1*28*28)/255\n#y = torch.nn.functional.one_hot(torch.tensor([0]*len(X0) + [1]*len(X1)+ [2]*len(X2))).float()\ny = torch.tensor([0]*len(X0) + [1]*len(X1)+ [2]*len(X2))\n## Step2: 학습가능한 오브젝트 생성\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,3),\n#    torch.nn.Softmax()\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n## Step3: 적합 \nfor epoc in range(100):\n    ## step1 \n    netout = net(X)\n    ## step2 \n    loss = loss_fn(netout,y)\n    ## step3 \n    loss.backward()\n    ## step4 \n    optimizr.step()\n    optimizr.zero_grad()\n## Step4: 적합 (혹은 적합결과확인)    \n(netout.argmax(axis=1) == y).float().mean()\n\ntensor(0.9827)\n\n\n파이토치에서 CrossEntropyLoss를 사용하면 one-hot 인코딩을 해준다. float형도 자동으로 맞춰줌"
  },
  {
    "objectID": "posts/DL_Summary2.html#c.-softmax",
    "href": "posts/DL_Summary2.html#c.-softmax",
    "title": "Deep Learning 2",
    "section": "C. Softmax",
    "text": "C. Softmax\n\nnet(X)\n\ntensor([[ 5.3554, -6.5855, -1.3154],\n        [ 3.2968, -4.6176, -1.0703],\n        [ 3.6498, -5.2716, -0.0403],\n        ...,\n        [-2.0524, -2.4955,  5.2198],\n        [-1.7430, -4.0844,  5.5187],\n        [-0.9800, -3.7222,  4.6707]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\nSoftmax는 숫자 하나하나에 접근해서 Sigmoid를 취해주는 것"
  },
  {
    "objectID": "posts/DL_Summary2.html#d.정리",
    "href": "posts/DL_Summary2.html#d.정리",
    "title": "Deep Learning 2",
    "section": "D.정리",
    "text": "D.정리\n- 결론\n\n소프트맥스는 시그모이드의 확장이다.\n클래스의 수가 2개일 경우에는 (Sigmoid, BCEloss) 조합을 사용해야 하고 클래스의 수가 2개보다 클 경우에는 (Softmax, CrossEntropyLoss) 를 사용해야 한다.\n\n- 그런데 사실.. 클래스의 수가 2개일 경우일때 (Softmax, CrossEntropyLoss)를 사용해도 그렇게 큰일나는것은 아니다. (그냥 좀 비효율적인 느낌이 드는 것 뿐임. 흑백이미지를 칼라잉크로 출력하는 느낌)"
  },
  {
    "objectID": "posts/DL_Summary2.html#b.-torch.nn.relu",
    "href": "posts/DL_Summary2.html#b.-torch.nn.relu",
    "title": "Deep Learning 2",
    "section": "B. torch.nn.ReLU()",
    "text": "B. torch.nn.ReLU()\n\na1 = torch.nn.ReLU()\n_X = torch.randn(25).reshape(1,1,5,5)\n_X,a1(_X)\n\n(tensor([[[[ 0.6092, -0.4852,  0.4315,  0.3735, -1.0661],\n           [-0.0087, -0.8282,  0.5311,  1.3330,  1.6749],\n           [ 0.0381, -0.7604, -0.0393, -0.0930, -0.2515],\n           [-1.4267,  0.7906,  2.4239, -0.7960, -0.0814],\n           [ 0.2651,  0.7082, -0.0816, -1.0088, -0.9553]]]]),\n tensor([[[[0.6092, 0.0000, 0.4315, 0.3735, 0.0000],\n           [0.0000, 0.0000, 0.5311, 1.3330, 1.6749],\n           [0.0381, 0.0000, 0.0000, 0.0000, 0.0000],\n           [0.0000, 0.7906, 2.4239, 0.0000, 0.0000],\n           [0.2651, 0.7082, 0.0000, 0.0000, 0.0000]]]]))\n\n\n음수인 수를 다 0으로 만든다"
  },
  {
    "objectID": "posts/DL_Summary2.html#c.-torch.nn.maxpood2d",
    "href": "posts/DL_Summary2.html#c.-torch.nn.maxpood2d",
    "title": "Deep Learning 2",
    "section": "C. torch.nn.MaxPood2d",
    "text": "C. torch.nn.MaxPood2d\n\nm1 = torch.nn.MaxPool2d((2,2))\n_X = torch.randn(25).reshape(1,1,5,5)\n_X,m1(_X)\n\n(tensor([[[[-0.1029, -0.7286,  0.9365,  0.4678,  0.6776],\n           [-0.7395, -0.7937,  0.8509, -0.1291,  2.2427],\n           [ 0.7738, -0.4895,  0.8041,  1.4233,  0.5733],\n           [ 0.7792, -0.4096, -1.5089,  0.3478,  1.1201],\n           [ 1.2056,  0.1269, -1.3804, -0.4759,  2.2051]]]]),\n tensor([[[[-0.1029,  0.9365],\n           [ 0.7792,  1.4233]]]]))\n\n\nfeature들을 요약하는 느낌"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": ".",
    "section": "",
    "text": "Deep Learning 2\n\n\n\n\n\n\n\n\n\n\n\nApr 9, 2024\n\n\n차상진\n\n\n\n\n\n\n\n\n\n\n\n\nDeep Learning 1\n\n\n\n\n\n\n\n\n\n\n\nApr 8, 2024\n\n\n차상진\n\n\n\n\n\n\nNo matching items"
  }
]