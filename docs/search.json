[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/DL_Summary4.html",
    "href": "posts/DL_Summary4.html",
    "title": "Deep Learning 4",
    "section": "",
    "text": "import torch \nimport torchvision\nimport fastai.vision.all\nimport matplotlib.pyplot as plt\nimport requests"
  },
  {
    "objectID": "posts/DL_Summary4.html#a.-dls",
    "href": "posts/DL_Summary4.html#a.-dls",
    "title": "Deep Learning 4",
    "section": "A. DLS",
    "text": "A. DLS\n\npath = fastai.data.external.untar_data(fastai.data.external.URLs.PETS)\nfnames = [l for l in (path/'images').ls() if str(l).split('.')[-1] == 'jpg']\n\n\ndef label_func(fname):\n    if fname[0].isupper():\n        return 'cat'\n    else:\n        return 'dog'\n\n\ndls = fastai.vision.data.ImageDataLoaders.from_name_func(\n    path = path/'images',\n    fnames = fnames,\n    label_func = label_func,\n    valid_pct = 0.2,\n    item_tfms = fastai.vision.augment.Resize(512),\n    bs = 32\n)\n\n\ndls.show_batch()"
  },
  {
    "objectID": "posts/DL_Summary4.html#b.-이미지-자료-불러오기",
    "href": "posts/DL_Summary4.html#b.-이미지-자료-불러오기",
    "title": "Deep Learning 4",
    "section": "B. 이미지 자료 불러오기",
    "text": "B. 이미지 자료 불러오기\n- torchvision 사용\n\nx = torchvision.io.read_image('/root/.fastai/data/oxford-iiit-pet/images/Sphynx_14.jpg')\n# x를 찍어보면 int형의 tensor형태로 되어있다\n\n- fastai 사용\npath를 이용하는 string \\(\\to\\) PILImage \\(\\to\\) fastai.torch_core.TensorImage \\(\\to\\) torch.tensor\n\nx_pil = fastai.vision.core.PILImage.create('/root/.fastai/data/oxford-iiit-pet/images/Sphynx_14.jpg')\nx = next(iter(dls.test_dl([x_pil])))[0]\n# x를 찍어보면 float형의 tensor형태로 되어있다"
  },
  {
    "objectID": "posts/DL_Summary4.html#c.-이미지-시각화",
    "href": "posts/DL_Summary4.html#c.-이미지-시각화",
    "title": "Deep Learning 4",
    "section": "C. 이미지 시각화",
    "text": "C. 이미지 시각화\n\nx_pil = fastai.vision.core.PILImage.create('/root/.fastai/data/oxford-iiit-pet/images/Sphynx_14.jpg')\nx = next(iter(dls.test_dl([x_pil])))[0] \nplt.imshow(torch.einsum('ocij -&gt; ijc' , x.to('cpu'))) # cuda에 있으면 시각화가 안 됨\n\n\n\n\n\n\n\n\n- 아무런 사진이나 하나 가져와서 시각화 해보기\n\nx_pil = fastai.vision.core.PILImage.create(requests.get('https://i.ytimg.com/vi/vc0aaS83cRo/maxresdefault.jpg').content)\nx = next(iter(dls.test_dl([x_pil])))[0]\nplt.imshow(torch.einsum('ocij -&gt; ijc' , x.to('cpu')))\n\n\n\n\n\n\n\n\niamge가 잘리는 이유 : dls에서 그림의 size를 512로 정해놨기때문에 512 x 512 image로 출력된다"
  },
  {
    "objectID": "posts/DL_Summary4.html#d.-ap-layer",
    "href": "posts/DL_Summary4.html#d.-ap-layer",
    "title": "Deep Learning 4",
    "section": "D. AP layer",
    "text": "D. AP layer\n\nap = torch.nn.AdaptiveAvgPool2d(output_size=1)\nap\n\nAdaptiveAvgPool2d(output_size=1)\n\n\n\nX = torch.arange(1*3*4*4).reshape(1,3,4,4)*1.0 \nX\n\ntensor([[[[ 0.,  1.,  2.,  3.],\n          [ 4.,  5.,  6.,  7.],\n          [ 8.,  9., 10., 11.],\n          [12., 13., 14., 15.]],\n\n         [[16., 17., 18., 19.],\n          [20., 21., 22., 23.],\n          [24., 25., 26., 27.],\n          [28., 29., 30., 31.]],\n\n         [[32., 33., 34., 35.],\n          [36., 37., 38., 39.],\n          [40., 41., 42., 43.],\n          [44., 45., 46., 47.]]]])\n\n\n\nap(X) #채널별로 평균을 구해줌\n\ntensor([[[[ 7.5000]],\n\n         [[23.5000]],\n\n         [[39.5000]]]])\n\n\n\nr,g,b = ap(X)[0]\n\n\nr, g ,b\n\n(tensor([[7.5000]]), tensor([[23.5000]]), tensor([[39.5000]]))"
  },
  {
    "objectID": "posts/DL_Summary4.html#e.-aplinear의-교환-linear는-행렬곱이다",
    "href": "posts/DL_Summary4.html#e.-aplinear의-교환-linear는-행렬곱이다",
    "title": "Deep Learning 4",
    "section": "E. AP,Linear의 교환 (Linear는 행렬곱이다)",
    "text": "E. AP,Linear의 교환 (Linear는 행렬곱이다)\n\nap(r)*0.1 + ap(g)*0.2 + ap(b)*0.3\n\ntensor([[17.3000]])\n\n\n\nap(r*0.1 + g*0.2 + b*0.3)\n\ntensor([[17.3000]])\n\n\n- 똑같은데요?\n위와 같은 과정을 Linear를 태울 때 l.weight와 같이 가중치를 적용하여서 합한다고 생각할 수 있다.\nl.weight.data = [0.1,0.2,0.3] 로 놓으면 생각하기가 조금 쉽다\n\nflttn = torch.nn.Flatten()\nl = torch.nn.Linear(3,1,bias=False)\nl.weight.data = torch.tensor([[0.1,0.2,0.3]]) # 행렬계산이기에 2차원 배열로 해야함\n\n우리가 쉽게 생각할 수 있는 1번째 방법\n\nl(flttn(ap(X)))\n\ntensor([[17.3000]], grad_fn=&lt;MmBackward0&gt;)\n\n\nLinear와 ap의 교환\n\nflttn(ap(torch.einsum('ocij,kc -&gt; okij' , X , l.weight.data)))\n\ntensor([[17.3000]])\n\n\n! Linear는 가중치를 곱해서 더하는 과정 즉, 행렬곱으로 이해하는 것이 좋다."
  },
  {
    "objectID": "posts/DL_Summary4.html#a.-1단계---이미지분류-잘하는-네트워크-선택-후-학습",
    "href": "posts/DL_Summary4.html#a.-1단계---이미지분류-잘하는-네트워크-선택-후-학습",
    "title": "Deep Learning 4",
    "section": "A. 1단계 - 이미지분류 잘하는 네트워크 선택 후 학습",
    "text": "A. 1단계 - 이미지분류 잘하는 네트워크 선택 후 학습\n\nlrnr = fastai.vision.learner.vision_learner(\n    dls = dls,\n    arch = fastai.vision.models.resnet34,\n    metrics = [fastai.metrics.accuracy]\n)\n\n\nlrnr.fine_tune(1) #lrnr.model의 마지막 부분만 학습시키는 걸 fine_tune이라고 함\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.087281\n0.012028\n0.995940\n00:19\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.051851\n0.010260\n0.996617\n00:26"
  },
  {
    "objectID": "posts/DL_Summary4.html#b.-2단계---네트워크-부분-수정-후-재학습",
    "href": "posts/DL_Summary4.html#b.-2단계---네트워크-부분-수정-후-재학습",
    "title": "Deep Learning 4",
    "section": "B. 2단계 - 네트워크 부분 수정 후 재학습",
    "text": "B. 2단계 - 네트워크 부분 수정 후 재학습\n\nnet1 = lrnr.model[0]\nnet2 = lrnr.model[1]\n\n\nnet2 = torch.nn.Sequential(\n    torch.nn.AdaptiveAvgPool2d(output_size=1),\n    torch.nn.Flatten(),\n    torch.nn.Linear(512,2,bias=False)\n)\n\n\nnet = torch.nn.Sequential(\n    net1,\n    net2\n) # 내가 만든(수정한) net\n\n\nlrnr2 = fastai.learner.Learner(\n    dls = dls,\n    model = net,\n    metrics = [fastai.metrics.accuracy]\n) # 나만의 net으로 새롭게 학습할 lrnr2\n\n\nlrnr.loss_func , lrnr2.loss_func # 정의하지 않아도 알아서 잘 들어가 있다\n\n(FlattenedLoss of CrossEntropyLoss(), FlattenedLoss of CrossEntropyLoss())\n\n\n\nlrnr2.fine_tune(5)\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.392073\n0.295664\n0.876861\n00:26\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.192747\n0.190745\n0.916779\n00:26\n\n\n1\n0.180415\n0.234511\n0.912720\n00:26\n\n\n2\n0.136703\n0.168526\n0.926252\n00:26\n\n\n3\n0.057196\n0.052161\n0.975643\n00:26\n\n\n4\n0.033394\n0.049159\n0.979702\n00:26"
  },
  {
    "objectID": "posts/DL_Summary4.html#c.-3단계---수정된-net2에서-linear-와-ap의-순서를-바꿈",
    "href": "posts/DL_Summary4.html#c.-3단계---수정된-net2에서-linear-와-ap의-순서를-바꿈",
    "title": "Deep Learning 4",
    "section": "C. 3단계 - 수정된 net2에서 linear 와 AP의 순서를 바꿈",
    "text": "C. 3단계 - 수정된 net2에서 linear 와 AP의 순서를 바꿈\n\nx_pil = fastai.vision.core.PILImage.create('/root/.fastai/data/oxford-iiit-pet/images/Sphynx_14.jpg')\nx = next(iter(dls.test_dl([x_pil])))[0]\nx_dec = dls.decode([x])[0]\nplt.imshow(torch.einsum('ocij -&gt; ijc', x_dec))\n\n\n\n\n\n\n\n\nnet2 순서 바꾸기 전 네트워크 진행\n\nap = lrnr2.model[-1][0]\nfl = lrnr2.model[-1][1]\nl = lrnr2.model[-1][2]\n\n\nl(fl(ap(net1(x)))) # 고양이!!\n\nTensorImage([[ 2.5441, -2.8503]], device='cuda:0', grad_fn=&lt;AliasBackward0&gt;)\n\n\n- net2 순서 바꾼 후 네트워크 진행\n\nap = lrnr2.model[-1][0]\nfl = lrnr2.model[-1][1]\nl = lrnr2.model[-1][2]\n\n1. 일단 net1(x)을 진행\n2. Linear를 먼저 해야하니 행렬곱\n3. ap\n4. flatten\n\nflttn(ap(torch.einsum('ocij,kc -&gt; okij' , net1(x) , l.weight.data))) #고양이!!!\n\nTensorImage([[ 2.5441, -2.8503]], device='cuda:0', grad_fn=&lt;AliasBackward0&gt;)\n\n\n- 그런데 왜 순서 바꾸는 거지..? 그냥 하면 안돼?\n- 순서를 바꾸면 데이터의 차원이 [1,2,?,?] 이런식으로 바뀌는데 2인 부분을 고양이 or 강아지 이런식으로 데이터를 바라볼 수 있다\n\nEXTRA. 잠깐… 인공지능이 뭘 보고 고양이인지 강아지인지 구분하는 거지?\n\nWHY = torch.einsum('ocij,kc -&gt; okij',net1(x),l.weight.data)\nWHY[0,0,:,:].int()\n\nTensorImage([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n             [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n             [ 0,  0,  0,  1,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0, -1, -2],\n             [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n             [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n             [ 0,  0,  0,  0,  0,  0,  3, 11, 16, 12,  4,  0,  0,  0,  0,  0],\n             [ 0,  0,  0,  0,  0,  0,  7, 26, 39, 29,  9,  0,  0,  0,  0,  0],\n             [ 0,  0,  0,  0,  0,  0,  9, 34, 53, 37, 10,  0,  0,  0,  0,  0],\n             [ 0,  0,  0,  0,  0,  0,  7, 27, 39, 28,  9,  0,  0,  0,  0,  0],\n             [ 0,  0,  0,  0,  0, -1,  3, 10, 15, 10,  3,  1,  1,  0,  0,  0],\n             [ 0,  0,  0,  0,  0,  0,  2,  4,  4,  2,  0,  0,  0,  0,  1,  0],\n             [ 0,  0,  0,  0,  0,  0,  4,  6,  8,  3,  0,  0,  1,  1,  1,  1],\n             [ 0,  0,  0,  0,  1,  1,  2,  8, 11,  4,  0,  0,  0,  1,  1,  0],\n             [ 0,  0,  0,  0,  0,  0,  2,  6,  7,  4,  0,  0,  0,  0,  0,  0],\n             [ 0,  0,  0,  0,  0,  0,  1,  2,  2,  1,  0,  0,  0,  0,  0,  0],\n             [ 0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0]],\n            device='cuda:0', dtype=torch.int32)\n\n\n- 가운데 쪽에 숫자들이 크다. 저 의미는 인공지능이 그림의 저 부분을 보고 고양이라고 판단했다는 의미\n\nWHY[0,1,:,:].int()\n\nTensorImage([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n                0,   0,   0],\n             [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n                0,   0,   0],\n             [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n                0,   0,   0],\n             [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n                1,   1,   0],\n             [  0,   0,   0,   0,   0,   0,   3,   8,   5,   1,   0,   0,   0,\n                0,   0,   0],\n             [  0,   0,   0,   0,  -3,  -9,  -8,   6,   5,   1,   0,   2,   3,\n                1,   0,   0],\n             [  0,   0,   0,  -1, -14, -42, -59, -42, -15,  -1,   0,   7,   4,\n                0,   0,   0],\n             [  0,   0,   0,  -2, -20, -65, -97, -72, -25,  -3,   0,   1,   1,\n                0,   0,   0],\n             [  0,   0,   0,  -2, -21, -64, -93, -71, -28,  -4,  -1,   0,   0,\n                0,   0,   0],\n             [  0,   0,   0,  -1, -12, -33, -45, -36, -15,  -3,  -1,  -1,   0,\n                0,   0,   1],\n             [  0,   0,   0,   0,  -3,  -8, -12,  -8,  -3,  -1,  -1,  -1,   0,\n                0,   0,   0],\n             [  0,   0,   0,   0,   0,  -2,  -5,  -1,   0,   0,   0,   0,   0,\n                0,   0,   0],\n             [  0,   0,   0,   0,   0,  -2,  -3,  -1,   0,   0,   0,   0,   0,\n                0,   0,   0],\n             [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n                0,   0,   0],\n             [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n                0,   0,   0],\n             [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n                0,   0,   0]], device='cuda:0', dtype=torch.int32)\n\n\n- 가운데 쪽에 숫자들이 작다. 저 의미는 인공지능이 그림의 저 부분을 보고 고양이가 아니라고 판단했다는 의미\n시각화 해보자\n\nWHYCAT = WHY[0,0,:,:].to('cpu').detach()\nWHYDOG = WHY[0,1,:,:].to('cpu').detach()\nx_dec = dls.decode([x])[0]\nfig , ax = plt.subplots(1,3,figsize=(8,4))\nax[0].imshow(torch.einsum('ocij -&gt; ijc',x_dec))\nax[1].imshow(WHYCAT , cmap='magma')\nax[2].imshow(WHYDOG , cmap='magma')\n\n\n\n\n\n\n\n\n\nfig ,ax = plt.subplots(1,2,figsize=(8,6))\nax[0].imshow(torch.einsum('ocij -&gt; ijc',x_dec))\nax[0].imshow(WHYCAT , cmap='magma',extent = (0,511,511,0) , interpolation = 'bilinear',alpha=0.5)\nax[1].imshow(torch.einsum('ocij -&gt; ijc',x_dec))\nax[1].imshow(WHYDOG , cmap='magma',extent = (0,511,511,0) , interpolation = 'bilinear',alpha=0.5)\n\n\n\n\n\n\n\n\n- 주로 눈을 보면서 고양이라고 판단하고 (1번째 그림의 해석) 주로 눈을 보면서 강아지가 아니라고 판단했다(2번째 그림의 해석)\n- 하니로 해보자\n\nx_pil = fastai.vision.core.PILImage.create(requests.get('https://github.com/guebin/DL2024/blob/main/imgs/01wk-hani1.jpeg?raw=true').content)\nx = next(iter(dls.test_dl([x_pil])))[0]\nx_dec = dls.decode([x])\nWHY = torch.einsum('ocij,kc -&gt; okij', net1(x), l.weight.data)\nWHYCAT = WHY[0,0,:,:].to(\"cpu\").detach()\nWHYDOG = WHY[0,1,:,:].to(\"cpu\").detach()\nsoftmax = torch.nn.Softmax(dim=1)\ncat_prob, dog_prob = softmax(flttn(ap(WHY))).to(\"cpu\").detach().tolist()[0]\n\n\nfig ,ax = plt.subplots(1,2,figsize=(8,6))\nax[0].imshow(torch.einsum('ocij -&gt; ijc',x_dec))\nax[0].imshow(WHYCAT , cmap='magma',extent = (0,511,511,0) , interpolation = 'bilinear',alpha=0.5)\nax[0].set_title(f'cat prob = {cat_prob:.6f}')\nax[1].imshow(torch.einsum('ocij -&gt; ijc',x_dec))\nax[1].imshow(WHYDOG , cmap='magma',extent = (0,511,511,0) , interpolation = 'bilinear',alpha=0.5)\nax[1].set_title(f'dog prob = {dog_prob:.6f}')\n\nText(0.5, 1.0, 'dog prob = 0.999923')"
  },
  {
    "objectID": "posts/DL_Summary4.html#d.-4단계---cam-시각화",
    "href": "posts/DL_Summary4.html#d.-4단계---cam-시각화",
    "title": "Deep Learning 4",
    "section": "D. 4단계 - CAM 시각화",
    "text": "D. 4단계 - CAM 시각화\n- 0~25번 사진\n\nfig,ax = plt.subplots(5,5)\nk = 0\nfor i in range(5):\n    for j in range(5):\n        x_pil = fastai.vision.core.PILImage.create(fnames[k])\n        x = next(iter(dls.test_dl([x_pil])))[0]\n        x_dec = dls.decode([x])\n        WHY = torch.einsum('ocij,kc -&gt; okij', net1(x), l.weight.data)\n        WHYCAT = WHY[0,0,:,:].to(\"cpu\").detach()\n        WHYDOG = WHY[0,1,:,:].to(\"cpu\").detach()\n        cat_prob, dog_prob = softmax(flttn(ap(WHY))).to(\"cpu\").detach().tolist()[0]\n        if cat_prob &gt; dog_prob:\n            ax[i][j].imshow(torch.einsum('ocij -&gt; ijc', x_dec))\n            ax[i][j].imshow(WHYCAT,cmap='magma',extent=(0,511,511,0),interpolation='bilinear',alpha=0.5)\n            ax[i][j].set_title(f\"cat({cat_prob:.2f})\")\n            ax[i][j].set_xticks([])\n            ax[i][j].set_yticks([])\n        else:\n            ax[i][j].imshow(torch.einsum('ocij -&gt; ijc', x_dec))\n            ax[i][j].imshow(WHYDOG,cmap='magma',extent=(0,511,511,0),interpolation='bilinear',alpha=0.5)\n            ax[i][j].set_title(f'dog({dog_prob:.2f})')\n            ax[i][j].set_xticks([])\n            ax[i][j].set_yticks([])\n        k = k+1\nfig.set_figheight(16)\nfig.set_figwidth(16)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n- 26~50번 사진\n\nfig,ax = plt.subplots(5,5)\n#---#\nk=25\nfor i in range(5):\n    for j in range(5):\n        x_pil = fastai.vision.core.PILImage.create(fastai.data.transforms.get_image_files(path/'images')[k])\n        x = next(iter(dls.test_dl([x_pil])))[0] # 이걸로 WHY를 만들어보자. \n        x_dec = dls.decode([x])[0] # 이걸로 시각화 \n        WHY = torch.einsum('ocij,kc -&gt; okij',net1(x),l.weight.data)\n        WHYCAT = WHY[0,0,:,:].to(\"cpu\").detach()\n        WHYDOG = WHY[0,1,:,:].to(\"cpu\").detach()\n        cat_prob, dog_prob = softmax(flttn(ap(WHY))).to(\"cpu\").detach().tolist()[0]\n        if cat_prob &gt; dog_prob: \n            ax[i][j].imshow(torch.einsum('ocij -&gt; ijc',x_dec))\n            ax[i][j].imshow(WHYCAT,cmap='magma',extent = (0,511,511,0), interpolation='bilinear',alpha=0.5)\n            ax[i][j].set_title(f\"cat({cat_prob:.2f})\")\n            ax[i][j].set_xticks([])\n            ax[i][j].set_yticks([])\n        else: \n            ax[i][j].imshow(torch.einsum('ocij -&gt; ijc',x_dec))\n            ax[i][j].imshow(WHYDOG,cmap='magma',extent = (0,511,511,0), interpolation='bilinear',alpha=0.5)\n            ax[i][j].set_title(f\"dog({dog_prob:.2f})\")\n            ax[i][j].set_xticks([])\n            ax[i][j].set_yticks([])            \n        k=k+1\nfig.set_figheight(16)\nfig.set_figwidth(16)\nfig.tight_layout() \n\n\n\n\n\n\n\n\n\n중요 WHY를 만드는 과정에서 Linear는 가중치를 곱하여 더하는 행위이고 행렬곱으로 계산된다.\n\n\n즉, einsum을 이용하여 계산해주면 된다\n\n\nl.weight.data의 값만 바꿔준다면 다른 가중치로도 계산할 수 있다."
  },
  {
    "objectID": "posts/DL_Summary2.html",
    "href": "posts/DL_Summary2.html",
    "title": "Deep Learning 2",
    "section": "",
    "text": "import torch\nimport matplotlib.pyplot as plt\nfrom fastai.data.all import *\nimport torchvision"
  },
  {
    "objectID": "posts/DL_Summary2.html#예시1-2층-히든레이어는-1층",
    "href": "posts/DL_Summary2.html#예시1-2층-히든레이어는-1층",
    "title": "Deep Learning 2",
    "section": "예시1 – 2층 (히든레이어는 1층)",
    "text": "예시1 – 2층 (히든레이어는 1층)\ntorch.nn.Sequential( torch.nn.Linear(??,??), ## &lt;– 학습해야할 가중치가 있는 층 torch.nn.ReLU(), torch.nn.Linear(??,??), ## &lt;– 학습해야할 가중치가 있는 층 )"
  },
  {
    "objectID": "posts/DL_Summary2.html#예시2-2층-히든레이어는-1층",
    "href": "posts/DL_Summary2.html#예시2-2층-히든레이어는-1층",
    "title": "Deep Learning 2",
    "section": "예시2 – 2층 (히든레이어는 1층)",
    "text": "예시2 – 2층 (히든레이어는 1층)\ntorch.nn.Sequential( torch.nn.Linear(??,??), ## &lt;– 학습해야할 가중치가 있는 층 torch.nn.ReLU(), torch.nn.Linear(??,??), ## &lt;– 학습해야할 가중치가 있는 층 torch.nn.Sigmoid(), )"
  },
  {
    "objectID": "posts/DL_Summary2.html#예시3-1층-히든레이어는-없음",
    "href": "posts/DL_Summary2.html#예시3-1층-히든레이어는-없음",
    "title": "Deep Learning 2",
    "section": "예시3 – 1층 (히든레이어는 없음!!)",
    "text": "예시3 – 1층 (히든레이어는 없음!!)\ntorch.nn.Sequential( torch.nn.Linear(??,??), ## &lt;– 학습해야할 가중치가 있는 층 )"
  },
  {
    "objectID": "posts/DL_Summary2.html#예시4-1층-히든레이어는-없음",
    "href": "posts/DL_Summary2.html#예시4-1층-히든레이어는-없음",
    "title": "Deep Learning 2",
    "section": "예시4 – 1층 (히든레이어는 없음!!)",
    "text": "예시4 – 1층 (히든레이어는 없음!!)\ntorch.nn.Sequential( torch.nn.Linear(??,??), ## &lt;– 학습해야할 가중치가 있는 층 torch.nn.Sigmoid() )"
  },
  {
    "objectID": "posts/DL_Summary2.html#예시5-3층-히든레이어는-2층",
    "href": "posts/DL_Summary2.html#예시5-3층-히든레이어는-2층",
    "title": "Deep Learning 2",
    "section": "예시5 – 3층 (히든레이어는 2층)",
    "text": "예시5 – 3층 (히든레이어는 2층)\ntorch.nn.Sequential( torch.nn.Linear(??,??), ## &lt;– 학습해야할 가중치가 있는 층 torch.nn.Sigmoid() torch.nn.Linear(??,??), ## &lt;– 학습해야할 가중치가 있는 층 torch.nn.Sigmoid() torch.nn.Linear(??,??), ## &lt;– 학습해야할 가중치가 있는 층\n)"
  },
  {
    "objectID": "posts/DL_Summary2.html#예시6-3층-히든레이어는-2층",
    "href": "posts/DL_Summary2.html#예시6-3층-히든레이어는-2층",
    "title": "Deep Learning 2",
    "section": "예시6 – 3층 (히든레이어는 2층)",
    "text": "예시6 – 3층 (히든레이어는 2층)\ntorch.nn.Sequential( torch.nn.Linear(??,??), ## &lt;– 학습해야할 가중치가 있는 층 torch.nn.ReLU() torch.nn.Dropout(??) torch.nn.Linear(??,??), ## &lt;– 학습해야할 가중치가 있는 층 torch.nn.ReLU() torch.nn.Dropout(??) torch.nn.Linear(??,??), ## &lt;– 학습해야할 가중치가 있는 층\ntorch.nn.Sigmoid() )"
  },
  {
    "objectID": "posts/DL_Summary2.html#a.-xy-데이터를-모두-굳이-gpu에-넘겨야-하는가",
    "href": "posts/DL_Summary2.html#a.-xy-데이터를-모두-굳이-gpu에-넘겨야-하는가",
    "title": "Deep Learning 2",
    "section": "A. X,y 데이터를 모두 굳이 GPU에 넘겨야 하는가?",
    "text": "A. X,y 데이터를 모두 굳이 GPU에 넘겨야 하는가?\n데이터셋을 짝홀로 나누어서 번갈아가면서 GPU에 올렸다 내렸다하면 안되나?\n- 아래의 알고리즘을 생각해보자.\n\n데이터를 반으로 나누고\n짝수 obs의 x,y,net의 모든 parameters을 GPU에 올린다\nyhat,loss,grad,update 수행\n홀수 obs의 x,y를 GPU메모리에서 내린다. 그리고 짝수 obs의 x,y를 GPU메모리에 올린다\nyhat,loss,grad,update 수행\n반복"
  },
  {
    "objectID": "posts/DL_Summary2.html#b.-미니배치-경사하강법",
    "href": "posts/DL_Summary2.html#b.-미니배치-경사하강법",
    "title": "Deep Learning 2",
    "section": "B. 미니배치 경사하강법",
    "text": "B. 미니배치 경사하강법\n그럼 홀수 짝수로 나누는 건 2로 나누는 건데 굳이 2로만 나누어야하나? 더 쪼갤 수 있지 않나?\n- gradient descent : 10개의 sample data가 있다고 할 때 모든 sample을 이용하여 slope계산\n- stochastic gradient descent with batch size = 1 : 10개의 smaple data를 하나씩으로 모두 쪼개서 slope계산\nstochastic gradient descent with batch size = 1의 경우는 epoc을 10번 하면 총 100번 epoc을 돌리는 것과 같다\n- stochastic gradient descent : m개의 sample을 이용하여 slope 계산\n그럼 stochastic gradient descent의 경우는 epoc을 10번 하면 총 40번 epoc을 돌리는 것과 같다."
  },
  {
    "objectID": "posts/DL_Summary2.html#c.-datasetds-dataloaderdl",
    "href": "posts/DL_Summary2.html#c.-datasetds-dataloaderdl",
    "title": "Deep Learning 2",
    "section": "C. Dataset(ds) , DataLoader(dl)",
    "text": "C. Dataset(ds) , DataLoader(dl)\nstochastic gradient descent를 수행하기 위해서 파이토치에서는 ds와 dl라는 오브젝트를 준비했다.\n\nx=torch.tensor(range(10)).float().reshape(-1,1)\ny=torch.tensor([1.0]*5+[0.0]*5).reshape(-1,1)\ntorch.concat([x,y],axis=1)\n\ntensor([[0., 1.],\n        [1., 1.],\n        [2., 1.],\n        [3., 1.],\n        [4., 1.],\n        [5., 0.],\n        [6., 0.],\n        [7., 0.],\n        [8., 0.],\n        [9., 0.]])\n\n\n\nds = torch.utils.data.TensorDataset(x,y)\n\ndir(ds)를 살펴보면 __getitem__이 있다 이러면 섭스크립터블하다는 것이다.\n\nds.tensors # 튜플 언패킹으로 뽑을 수 있을 거 같음\n\n(tensor([[0.],\n         [1.],\n         [2.],\n         [3.],\n         [4.],\n         [5.],\n         [6.],\n         [7.],\n         [8.],\n         [9.]]),\n tensor([[1.],\n         [1.],\n         [1.],\n         [1.],\n         [1.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [0.]]))\n\n\n\nds[0] , (x,y)[0]\n\n((tensor([0.]), tensor([1.])),\n tensor([[0.],\n         [1.],\n         [2.],\n         [3.],\n         [4.],\n         [5.],\n         [6.],\n         [7.],\n         [8.],\n         [9.]]))\n\n\n그런데 일반적인 튜플의 인덱싱과는 다르게 동작함\n\ndl=torch.utils.data.DataLoader(ds,batch_size=3)\ndl\n\n&lt;torch.utils.data.dataloader.DataLoader at 0x7fdf9fc2fec0&gt;\n\n\ndl : 섭스크립터블하지 않지만 이터러블 함 즉, for문을 사용할 수 있음\n\nfor xi,yi in dl:\n    print(xi,yi)\n\ntensor([[0.],\n        [1.],\n        [2.]]) tensor([[1.],\n        [1.],\n        [1.]])\ntensor([[3.],\n        [4.],\n        [5.]]) tensor([[1.],\n        [1.],\n        [0.]])\ntensor([[6.],\n        [7.],\n        [8.]]) tensor([[0.],\n        [0.],\n        [0.]])\ntensor([[9.]]) tensor([[0.]])\n\n\n10을 3으로 나누면 마지막에 하나 남는데 그건 어떻게 해? -&gt; 그냥 하나 남으면 그것만 계산한다"
  },
  {
    "objectID": "posts/DL_Summary2.html#d.-dsdl을-이용한-mnist구현",
    "href": "posts/DL_Summary2.html#d.-dsdl을-이용한-mnist구현",
    "title": "Deep Learning 2",
    "section": "D. ds,dl을 이용한 MNIST구현",
    "text": "D. ds,dl을 이용한 MNIST구현\n- 목표 : 확률적경사하강법과 그냥 경사하강법의 성능을 ’동일 반복횟수’로 비교해보자\n- 그냥 경사하강법 - mini-batch쓰지 않는 학습\n\npath = untar_data(URLs.MNIST)\nX0 = torch.stack(([torchvision.io.read_image(str(fname)) for fname in (path/'training/0').ls()]))\nX1 = torch.stack(([torchvision.io.read_image(str(fname)) for fname in (path/'training/1').ls()]))\nX = torch.concat([X0,X1],axis=0).reshape(-1,1*28*28)/255\ny = torch.tensor([0.0]*len(X0) + [1.0]*len(X1)).reshape(-1,1)\n\ntorch.manual_seed(21345)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1*28*28,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n)\n\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\nfor epoc in range(700):\n    yhat = net(X)\n    loss = loss_fn(yhat,y)\n    loss.backward()\n    optimizr.step()\n    optimizr.zero_grad()\n\n((yhat &gt; 0.5)*1.0 == y).float().mean()\n\ntensor(0.9998)\n\n\n\nplt.plot(y)\nplt.plot(yhat.data,'.')\n\n\n\n\n\n\n\n\n- ‘확률적’ 경사하강법 - mini-batch사용하는 학습\n\nds = torch.utils.data.TensorDataset(X,y)\ndl = torch.utils.data.DataLoader(ds,batch_size=2048)\n\npath = untar_data(URLs.MNIST)\nX0 = torch.stack(([torchvision.io.read_image(str(fname)) for fname in (path/'training/0').ls()]))\nX1 = torch.stack(([torchvision.io.read_image(str(fname)) for fname in (path/'training/1').ls()]))\nX = torch.concat([X0,X1],axis=0).reshape(-1,1*28*28)/255\ny = torch.tensor([0.0]*len(X0) + [1.0]*len(X1)).reshape(-1,1)\n\ntorch.manual_seed(21345)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1*28*28,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n)\n\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\nfor epoc in range(100):\n    for xi,yi in dl:\n        netout = net(xi)\n        loss = loss_fn(netout,yi)\n        loss.backward()\n        optimizr.step()\n        optimizr.zero_grad()\n\n((net(X) &gt; 0.5)*1.0 == y).float().mean()\n\ntensor(0.9992)\n\n\n\nplt.plot(y)\nplt.plot(yhat.data,'.')\n\n\n\n\n\n\n\n\n- GPU를 활용하는 ‘확률적’ 경사하강법 - 실제로는 이게 최종 알고리즘\n\nds = torch.utils.data.TensorDataset(X,y)\ndl = torch.utils.data.DataLoader(ds,batch_size=2048)\n\npath = untar_data(URLs.MNIST)\nX0 = torch.stack(([torchvision.io.read_image(str(fname)) for fname in (path/'training/0').ls()]))\nX1 = torch.stack(([torchvision.io.read_image(str(fname)) for fname in (path/'training/1').ls()]))\nX = torch.concat([X0,X1],axis=0).reshape(-1,1*28*28)/255\ny = torch.tensor([0.0]*len(X0) + [1.0]*len(X1)).reshape(-1,1)\n\ntorch.manual_seed(21345)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1*28*28,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n).to(\"cuda:0\")\n\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\nfor epoc in range(100):\n    for xi,yi in dl:\n        loss = loss_fn(net(xi.to(\"cuda:0\")),yi.to(\"cuda:0\"))\n        loss.backward()\n        optimizr.step()\n        optimizr.zero_grad()\n\nnet.to(\"cpu\")\n\n((net(X) &gt; 0.5)*1.0 == y).float().mean()\n\ntensor(0.9992)\n\n\n\nplt.plot(y)\nplt.plot(net(X).data.data,'.')"
  },
  {
    "objectID": "posts/DL_Summary2.html#a.-결론그냥-외워",
    "href": "posts/DL_Summary2.html#a.-결론그냥-외워",
    "title": "Deep Learning 2",
    "section": "A. 결론(그냥 외워)",
    "text": "A. 결론(그냥 외워)\n- 2개의 class를 구분하는 게 아니라 k개의 class를 구분해야 한다면?\ny의 형태 : (n,) vector + int형 // (n,k) one-hot encoded matrix + float형\n손실함수 : torch.nn.BCEWithLogitsLoss, -&gt; torch.nn.CrossEntropyLoss\n마지막층의 선형변환 : torch.nn.Linear(?,1) -&gt; torch.nn.Linear(?,k)\n마지막층의 활성화 : NONE -&gt; NONE (손실함수에 이미 포함되어있음)"
  },
  {
    "objectID": "posts/DL_Summary2.html#b.-실습-3개의-클래스를-구분",
    "href": "posts/DL_Summary2.html#b.-실습-3개의-클래스를-구분",
    "title": "Deep Learning 2",
    "section": "B. 실습 : 3개의 클래스를 구분",
    "text": "B. 실습 : 3개의 클래스를 구분\n- 1. 통계는 잘하는데 파이토치를 못하는 사람의 코드\n\n## Step1: 데이터준비 \npath = untar_data(URLs.MNIST)\nX0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/0').ls()])\nX1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/1').ls()])\nX2 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/2').ls()])\nX = torch.concat([X0,X1,X2]).reshape(-1,1*28*28)/255\ny = torch.nn.functional.one_hot(torch.tensor([0]*len(X0) + [1]*len(X1)+ [2]*len(X2))).float()\n## Step2: 학습가능한 오브젝트 생성\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,3),\n#    torch.nn.Softmax()\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n## Step3: 적합 \nfor epoc in range(100):\n    ## step1 \n    netout = net(X)\n    ## step2 \n    loss = loss_fn(netout,y)\n    ## step3 \n    loss.backward()\n    ## step4 \n    optimizr.step()\n    optimizr.zero_grad()\n    \n## Step4: 적합 (혹은 적합결과확인)\n(netout.argmax(axis=1) == y.argmax(axis=1)).float().mean()\n\ntensor(0.9827)\n\n\n- 2. 파이토치를 잘하는 사람의 코드\n\n## Step1: 데이터준비 \npath = untar_data(URLs.MNIST)\nX0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/0').ls()])\nX1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/1').ls()])\nX2 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/2').ls()])\nX = torch.concat([X0,X1,X2]).reshape(-1,1*28*28)/255\n#y = torch.nn.functional.one_hot(torch.tensor([0]*len(X0) + [1]*len(X1)+ [2]*len(X2))).float()\ny = torch.tensor([0]*len(X0) + [1]*len(X1)+ [2]*len(X2))\n## Step2: 학습가능한 오브젝트 생성\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,3),\n#    torch.nn.Softmax()\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n## Step3: 적합 \nfor epoc in range(100):\n    ## step1 \n    netout = net(X)\n    ## step2 \n    loss = loss_fn(netout,y)\n    ## step3 \n    loss.backward()\n    ## step4 \n    optimizr.step()\n    optimizr.zero_grad()\n## Step4: 적합 (혹은 적합결과확인)    \n(netout.argmax(axis=1) == y).float().mean()\n\ntensor(0.9827)\n\n\n파이토치에서 CrossEntropyLoss를 사용하면 one-hot 인코딩을 해준다. float형도 자동으로 맞춰줌"
  },
  {
    "objectID": "posts/DL_Summary2.html#c.-softmax",
    "href": "posts/DL_Summary2.html#c.-softmax",
    "title": "Deep Learning 2",
    "section": "C. Softmax",
    "text": "C. Softmax\n\nnet(X)\n\ntensor([[ 5.3554, -6.5855, -1.3154],\n        [ 3.2968, -4.6176, -1.0703],\n        [ 3.6498, -5.2716, -0.0403],\n        ...,\n        [-2.0524, -2.4955,  5.2198],\n        [-1.7430, -4.0844,  5.5187],\n        [-0.9800, -3.7222,  4.6707]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\nSoftmax는 숫자 하나하나에 접근해서 Sigmoid를 취해주는 것"
  },
  {
    "objectID": "posts/DL_Summary2.html#d.정리",
    "href": "posts/DL_Summary2.html#d.정리",
    "title": "Deep Learning 2",
    "section": "D.정리",
    "text": "D.정리\n- 결론\n\n소프트맥스는 시그모이드의 확장이다.\n클래스의 수가 2개일 경우에는 (Sigmoid, BCEloss) 조합을 사용해야 하고 클래스의 수가 2개보다 클 경우에는 (Softmax, CrossEntropyLoss) 를 사용해야 한다.\n\n- 그런데 사실.. 클래스의 수가 2개일 경우일때 (Softmax, CrossEntropyLoss)를 사용해도 그렇게 큰일나는것은 아니다. (그냥 좀 비효율적인 느낌이 드는 것 뿐임. 흑백이미지를 칼라잉크로 출력하는 느낌)"
  },
  {
    "objectID": "posts/DL_Summary2.html#b.-torch.nn.relu",
    "href": "posts/DL_Summary2.html#b.-torch.nn.relu",
    "title": "Deep Learning 2",
    "section": "B. torch.nn.ReLU()",
    "text": "B. torch.nn.ReLU()\n\na1 = torch.nn.ReLU()\n_X = torch.randn(25).reshape(1,1,5,5)\n_X,a1(_X)\n\n(tensor([[[[ 0.6092, -0.4852,  0.4315,  0.3735, -1.0661],\n           [-0.0087, -0.8282,  0.5311,  1.3330,  1.6749],\n           [ 0.0381, -0.7604, -0.0393, -0.0930, -0.2515],\n           [-1.4267,  0.7906,  2.4239, -0.7960, -0.0814],\n           [ 0.2651,  0.7082, -0.0816, -1.0088, -0.9553]]]]),\n tensor([[[[0.6092, 0.0000, 0.4315, 0.3735, 0.0000],\n           [0.0000, 0.0000, 0.5311, 1.3330, 1.6749],\n           [0.0381, 0.0000, 0.0000, 0.0000, 0.0000],\n           [0.0000, 0.7906, 2.4239, 0.0000, 0.0000],\n           [0.2651, 0.7082, 0.0000, 0.0000, 0.0000]]]]))\n\n\n음수인 수를 다 0으로 만든다"
  },
  {
    "objectID": "posts/DL_Summary2.html#c.-torch.nn.maxpood2d",
    "href": "posts/DL_Summary2.html#c.-torch.nn.maxpood2d",
    "title": "Deep Learning 2",
    "section": "C. torch.nn.MaxPood2d",
    "text": "C. torch.nn.MaxPood2d\n\nm1 = torch.nn.MaxPool2d((2,2))\n_X = torch.randn(25).reshape(1,1,5,5)\n_X,m1(_X)\n\n(tensor([[[[-0.1029, -0.7286,  0.9365,  0.4678,  0.6776],\n           [-0.7395, -0.7937,  0.8509, -0.1291,  2.2427],\n           [ 0.7738, -0.4895,  0.8041,  1.4233,  0.5733],\n           [ 0.7792, -0.4096, -1.5089,  0.3478,  1.1201],\n           [ 1.2056,  0.1269, -1.3804, -0.4759,  2.2051]]]]),\n tensor([[[[-0.1029,  0.9365],\n           [ 0.7792,  1.4233]]]]))\n\n\nfeature들을 요약하는 느낌"
  },
  {
    "objectID": "posts/DL_Summary3.html",
    "href": "posts/DL_Summary3.html",
    "title": "Deep Learning 3",
    "section": "",
    "text": "import torch\nimport torchvision\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom fastai.data.all import *\nfrom fastai.vision.all import * \nimport fastai"
  },
  {
    "objectID": "posts/DL_Summary3.html#a.-transpose",
    "href": "posts/DL_Summary3.html#a.-transpose",
    "title": "Deep Learning 3",
    "section": "A. transpose",
    "text": "A. transpose\n\ntsr = torch.arange(12).reshape(4,3)\ntsr\n\ntensor([[ 0,  1,  2],\n        [ 3,  4,  5],\n        [ 6,  7,  8],\n        [ 9, 10, 11]])\n\n\n- 1번 방법\n\ntsr.t()\n\ntensor([[ 0,  3,  6,  9],\n        [ 1,  4,  7, 10],\n        [ 2,  5,  8, 11]])\n\n\n- 2번 방법\n\ntorch.einsum('ij -&gt; ji' ,tsr)\n\ntensor([[ 0,  3,  6,  9],\n        [ 1,  4,  7, 10],\n        [ 2,  5,  8, 11]])\n\n\n1번이 더 쉬운데..? 왜 2번처럼 해야할까?"
  },
  {
    "objectID": "posts/DL_Summary3.html#b.-행렬곱",
    "href": "posts/DL_Summary3.html#b.-행렬곱",
    "title": "Deep Learning 3",
    "section": "B. 행렬곱",
    "text": "B. 행렬곱\n\ntsr1 = torch.arange(12).reshape(4,3).float()\ntsr2 = torch.arange(15).reshape(3,5).float()\n\n\ntsr1 @ tsr2\n\ntensor([[ 25.,  28.,  31.,  34.,  37.],\n        [ 70.,  82.,  94., 106., 118.],\n        [115., 136., 157., 178., 199.],\n        [160., 190., 220., 250., 280.]])\n\n\n\ntorch.einsum('ij,jk -&gt; ik' ,tsr1,tsr2)\n\ntensor([[ 25.,  28.,  31.,  34.,  37.],\n        [ 70.,  82.,  94., 106., 118.],\n        [115., 136., 157., 178., 199.],\n        [160., 190., 220., 250., 280.]])\n\n\nMatrix의 차원만 잘 지정하고 데이터를 적는다면 쉽게 행렬곱을 수행해준다."
  },
  {
    "objectID": "posts/DL_Summary3.html#c.-이미지-변환",
    "href": "posts/DL_Summary3.html#c.-이미지-변환",
    "title": "Deep Learning 3",
    "section": "C. 이미지 변환",
    "text": "C. 이미지 변환\n\nr = torch.zeros(16).reshape(4,4) + 1.0\ng = torch.zeros(16).reshape(4,4)\nb = torch.zeros(16).reshape(4,4)\nimg_plt = torch.stack([r,g,b],axis=-1) # matplotlib 를 쓰기 위해서는 이미지가 이렇게 저장되어있어야한다. \nimg_torch = torch.stack([r,g,b],axis=0).reshape(1,3,4,4) # torch를 쓰기 위해서는 이미지가 이렇게 저장되어있어야한다. \n\n\n# 잘못된코드\nplt.imshow(img_torch.reshape(4,4,3))\n\n\n\n\n\n\n\n\n\n# 올바른코드\nplt.imshow(torch.einsum('ocij -&gt; ijc',img_torch))\n\n\n\n\n\n\n\n\n원하는 건 빨간 배경인데 행렬곱을 위처럼 수행하면 프레임이 깨진다."
  },
  {
    "objectID": "posts/DL_Summary3.html#a.-yn3---float형",
    "href": "posts/DL_Summary3.html#a.-yn3---float형",
    "title": "Deep Learning 3",
    "section": "A. y:(n,3) - float형",
    "text": "A. y:(n,3) - float형\n\nds = torch.utils.data.TensorDataset(X,y)\ndl = torch.utils.data.DataLoader(ds,batch_size=128)\n\nnet1 = torch.nn.Sequential(\n    torch.nn.Conv2d(1,16,(5,5)),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d((2,2)),\n    torch.nn.Flatten()\n)\n\nnet2 = torch.nn.Sequential(\n    torch.nn.Linear(2304,3)\n)\nnet = torch.nn.Sequential(\n    net1,\n    net2\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\nnet.to('cuda:0')\nfor epoc in range(10):\n    for xi,yi in dl:\n        loss = loss_fn(net(xi.to('cuda:0')),yi.to('cuda:0'))\n        loss.backward()\n        optimizr.step()\n        optimizr.zero_grad()\n\nnet.to('cpu')\n\nprint(f'train : {(net(X).data.argmax(axis=1) == y.argmax(axis=1)).float().mean():.4f}')\nprint(f'val : {(net(XX).data.argmax(axis=1) == yy.argmax(axis=1)).float().mean():.4f}')\n\ntrain : 0.9812\nval : 0.9873\n\n\n- 항상 하던 것."
  },
  {
    "objectID": "posts/DL_Summary3.html#b.-yn---int형",
    "href": "posts/DL_Summary3.html#b.-yn---int형",
    "title": "Deep Learning 3",
    "section": "B. y:(n,) - int형",
    "text": "B. y:(n,) - int형\n\nX0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in list(Path('/root/.fastai/data/mnist_png/training/0').ls())])\nX1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in list(Path('/root/.fastai/data/mnist_png/training/1').ls())])\nX2 = torch.stack([torchvision.io.read_image(str(fname)) for fname in list(Path('/root/.fastai/data/mnist_png/training/2').ls())])\nX = torch.concat([X0,X1,X2],axis=0)/255\ny = torch.nn.functional.one_hot(torch.tensor([0]*len(X0) + [1]*len(X1) + [2]*len(X2))).float()\nXX0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in list(Path('/root/.fastai/data/mnist_png/testing/0').ls())])\nXX1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in list(Path('/root/.fastai/data/mnist_png/testing/1').ls())])\nXX2 = torch.stack([torchvision.io.read_image(str(fname)) for fname in list(Path('/root/.fastai/data/mnist_png/testing/2').ls())])\nXX = torch.concat([XX0,XX1,XX2],axis=0)/255\nyy = torch.nn.functional.one_hot(torch.tensor([0]*len(XX0) + [1]*len(XX1) + [2]*len(XX2))).float()\n\n\ny = y.argmax(axis=-1)\nyy = yy.argmax(axis=-1)\n\ny와 yy를 int형으로 바꿔야하기에 argmax함수를 이용했다.\n\nprint(X.shape)\nprint(y.shape)\nprint(XX.shape)\nprint(yy.shape)\n\ntorch.Size([60000, 1, 28, 28])\ntorch.Size([60000])\ntorch.Size([10000, 1, 28, 28])\ntorch.Size([10000])\n\n\n\nds = torch.utils.data.TensorDataset(X,y)\ndl = torch.utils.data.DataLoader(ds,batch_size=128)\n\nnet1 =  torch.nn.Sequential(\n    torch.nn.Conv2d(1,16,(5,5)),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d((2,2)),\n    torch.nn.Flatten()\n)\nnet2 = torch.nn.Sequential(\n    torch.nn.Linear(2304,3)\n)\nnet = torch.nn.Sequential(\n    net1,\n    net2\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\nnet.to('cuda:0')\nfor epoc in range(10):\n    for xi,yi in dl:\n        # netout = net(xi.to('cuda:0'))\n        loss = loss_fn(net(xi.to('cuda:0')),yi.to('cuda:0'))\n        loss.backward()\n        optimizr.step()\n        optimizr.zero_grad()\nnet.to(\"cpu\")\nprint(f'train : {(net(X).data.argmax(axis=1) == y).float().mean():.4f}')\nprint(f'val : {(net(XX).data.argmax(axis=1) == yy).float().mean():.4f}')\n\ntrain : 0.9767\nval : 0.9854\n\n\n- 손실함수로 torch.nn.CrossEntropyLoss()를 사용하면 one_hot_encoding , float형 전처리 모두 필요없다 알아서 다 해줌\n- 받아야하는 class가 1보다 크면 CrossEntropyLoss()를 사용"
  },
  {
    "objectID": "posts/DL_Summary3.html#a.-torch",
    "href": "posts/DL_Summary3.html#a.-torch",
    "title": "Deep Learning 3",
    "section": "A. torch",
    "text": "A. torch\n\nds = torch.utils.data.TensorDataset(X,y)\ndl = torch.utils.data.DataLoader(ds,batch_size=128)\n\nnet1 = torch.nn.Sequential(\n    torch.nn.Conv2d(1,16,(5,5)),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d((2,2)),\n    torch.nn.Flatten()\n)\nnet2 = torch.nn.Sequential(\n    torch.nn.Linear(2304,10)\n)\nnet = torch.nn.Sequential(\n    net1,\n    net2\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\nnet.to('cuda:0')\nfor epoc in range(10):\n    for xi,yi in dl:\n        netout = net(xi.to('cuda:0'))\n        loss = loss_fn(netout,yi.to('cuda:0'))\n        loss.backward()\n        optimizr.step()\n        optimizr.zero_grad()\nnet.to('cpu')\n\nprint(f'train: {(net(X).data.argmax(axis=1) == y).float().mean():.4f}')\nprint(f'val: {(net(XX).data.argmax(axis=1) == yy).float().mean():.4f}')\n\ntrain: 0.9089\nval: 0.8701\n\n\n- 항상 하던 것\n- 받아야하는 class가 10개니까 torch.nn.CrossEntropyLoss() 사용하고 어자피 float형 안 맞춰도 되니까 y를 int형으로 설정"
  },
  {
    "objectID": "posts/DL_Summary3.html#b.-fastai",
    "href": "posts/DL_Summary3.html#b.-fastai",
    "title": "Deep Learning 3",
    "section": "B. fastai",
    "text": "B. fastai\n\n# Step1: 데이터정리 (dls생성)\nds1 = torch.utils.data.TensorDataset(X,y)\nds2 = torch.utils.data.TensorDataset(XX,yy)\ndl1 = torch.utils.data.DataLoader(ds1,batch_size=128)\ndl2 = torch.utils.data.DataLoader(ds2,batch_size=128)\ndls = fastai.data.core.DataLoaders(dl1,dl2)\n# Step2: 적합에 필요한 오브젝트 생성\nnet1 = torch.nn.Sequential(\n    torch.nn.Conv2d(1,16,(5,5)),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d((2,2)),\n    torch.nn.Flatten()\n)\nnet2 = torch.nn.Sequential(\n    torch.nn.Linear(2304,10),\n)\nnet = torch.nn.Sequential(\n    net1, # 2d-part\n    net2, # 1d-part \n)\nloss_fn = torch.nn.CrossEntropyLoss()\n# optimizr = torch.optim.Adam(net.parameters())\n# Step3: 적합 \nlrnr = fastai.learner.Learner(\n    dls=dls,\n    model = net,\n    loss_func = loss_fn,\n    metrics = [fastai.metrics.accuracy]\n)\n\nlrnr.fit(10)\n\n# Step4: 예측 및 평가 \nlrnr.model.to('cpu')\n\nprint(f'train: {(net(X).data.argmax(axis=1) == y).float().mean():.4f}')\nprint(f'val: {(net(XX).data.argmax(axis=1) == yy).float().mean():.4f}')\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.541958\n0.464602\n0.851200\n00:01\n\n\n1\n0.402498\n0.436741\n0.859500\n00:01\n\n\n2\n0.353617\n0.427963\n0.865000\n00:01\n\n\n3\n0.319062\n0.429699\n0.869100\n00:01\n\n\n4\n0.297310\n0.442318\n0.869700\n00:01\n\n\n5\n0.284193\n0.457588\n0.870200\n00:01\n\n\n6\n0.275215\n0.462712\n0.873100\n00:01\n\n\n7\n0.264285\n0.461538\n0.872100\n00:01\n\n\n8\n0.260774\n0.467244\n0.874800\n00:01\n\n\n9\n0.253124\n0.481810\n0.874100\n00:01\n\n\n\n\n\n\ntrain: 0.9161\nval: 0.8741\n\n\n- 조금 새롭게 fastai 이용\noptimizr 사용 안 해도 된다. lrnr 새롭게 정의해서 손실함수 넣어주고 원하는 적합기준 정해주면 된다.\nfor epoc 귀찮게 길게 쓸 필요 없이 fit하면 바로 학습\nlrnr 사용하면 to.(‘cuda:0’) 사용 할 필요없이 바로 GPU로 연산해준다."
  },
  {
    "objectID": "posts/DL_Summary3.html#a.-데이터-불러오기-및-전처리",
    "href": "posts/DL_Summary3.html#a.-데이터-불러오기-및-전처리",
    "title": "Deep Learning 3",
    "section": "A. 데이터 불러오기 및 전처리",
    "text": "A. 데이터 불러오기 및 전처리\n\npath = fastai.data.external.untar_data(fastai.data.external.URLs.CIFAR)\npath.ls()\n\n(#3) [Path('/root/.fastai/data/cifar10/train'),Path('/root/.fastai/data/cifar10/labels.txt'),Path('/root/.fastai/data/cifar10/test')]\n\n\n\nlabels = [str(l).split('/')[-1] for l in (path/'train').ls()]\nlabels\n\n['deer',\n 'airplane',\n 'ship',\n 'dog',\n 'automobile',\n 'truck',\n 'cat',\n 'frog',\n 'horse',\n 'bird']\n\n\n\nX = torch.stack([torchvision.io.read_image(str(fname)) for l in labels for fname in (path/f'train/{l}').ls()],axis=0).float()/255\nXX = torch.stack([torchvision.io.read_image(str(fname)) for l in labels for fname in (path/f'test/{l}').ls()],axis=0).float()/255\ny = torch.tensor([i for i,l in enumerate(labels) for fname in (path/f'train/{l}').ls()])\nyy = torch.tensor([i for i,l in enumerate(labels) for fname in (path/f'test/{l}').ls()])\n\n\nprint(X.shape,'\\t',X.dtype)\nprint(y.shape,'\\t\\t\\t',y.dtype)\nprint(XX.shape,'\\t',XX.dtype)\nprint(yy.shape,'\\t\\t\\t',yy.dtype)\n\ntorch.Size([50000, 3, 32, 32])   torch.float32\ntorch.Size([50000])              torch.int64\ntorch.Size([10000, 3, 32, 32])   torch.float32\ntorch.Size([10000])              torch.int64\n\n\n\nylabel = [l for l in labels for fname in (path/f'train/{l}').ls()]\ni = 30002\nplt.imshow(torch.einsum('cij-&gt;ijc',X[i]))\nplt.title(f'{ylabel[i]},{y[i]}')\n\nText(0.5, 1.0, 'cat,6')\n\n\n\n\n\n\n\n\n\n- 쓰읍…뭐지? 어렵겠는데?\n\nds1 = torch.utils.data.TensorDataset(X,y)\nds2 = torch.utils.data.TensorDataset(XX,yy)\ndl1 = torch.utils.data.DataLoader(ds1,batch_size=256,shuffle=True)\ndl2 = torch.utils.data.DataLoader(ds2,batch_size=100)\ndls = fastai.data.core.DataLoaders(dl1,dl2)"
  },
  {
    "objectID": "posts/DL_Summary3.html#b.-수제네트워크로-학습",
    "href": "posts/DL_Summary3.html#b.-수제네트워크로-학습",
    "title": "Deep Learning 3",
    "section": "B. 수제네트워크로 학습",
    "text": "B. 수제네트워크로 학습\n\n# Step1:\nds1 = torch.utils.data.TensorDataset(X,y)\nds2 = torch.utils.data.TensorDataset(XX,yy)\ndl1 = torch.utils.data.DataLoader(ds1,batch_size=256)\ndl2 = torch.utils.data.DataLoader(ds2,batch_size=100)\ndls = fastai.data.core.DataLoaders(dl1,dl2)\n# Step2:\nnet1 = torch.nn.Sequential(\n    torch.nn.Conv2d(3,16,(5,5)),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d((2,2)),\n    torch.nn.Flatten()\n)\nnet2 = torch.nn.Sequential(\n    torch.nn.Linear(3136,10),\n)\nnet = torch.nn.Sequential(\n    net1, # 2d-part\n    net2, # 1d-part \n)\nloss_fn = torch.nn.CrossEntropyLoss()\nlrnr = fastai.learner.Learner(\n    dls=dls,\n    model=net,\n    loss_func=loss_fn,\n    #--#\n    metrics=[fastai.metrics.accuracy]\n)\n# Step3:\nlrnr.fit(10)\n# Step4: \nlrnr.model.to(\"cpu\")\nprint(f'train: {(lrnr.model(X).data.argmax(axis=1) == y).float().mean():.4f}')\nprint(f'val: {(lrnr.model(XX).data.argmax(axis=1) == yy).float().mean():.4f}')\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n2.433561\n2.301266\n0.111900\n00:00\n\n\n1\n2.410473\n2.299356\n0.111600\n00:00\n\n\n2\n2.479004\n2.294760\n0.129800\n00:00\n\n\n3\n2.709449\n2.291229\n0.132000\n00:01\n\n\n4\n2.522834\n2.285669\n0.141500\n00:00\n\n\n5\n2.564267\n2.291603\n0.152500\n00:00\n\n\n6\n2.335277\n22.824865\n0.100000\n00:00\n\n\n7\n2.451625\n2.266450\n0.154900\n00:00\n\n\n8\n2.779048\n2.276835\n0.134400\n00:00\n\n\n9\n2.322695\n15.980297\n0.100000\n00:01\n\n\n\n\n\n\ntrain: 0.1000\nval: 0.1000\n\n\n- 적합결과가… 너무….낮은데?\n- shuffle 해보자\n\n# Step1:\nds1 = torch.utils.data.TensorDataset(X,y)\nds2 = torch.utils.data.TensorDataset(XX,yy)\ndl1 = torch.utils.data.DataLoader(ds1,batch_size=256,shuffle=True)\ndl2 = torch.utils.data.DataLoader(ds2,batch_size=100)\ndls = fastai.data.core.DataLoaders(dl1,dl2)\n# Step2:\nnet1 = torch.nn.Sequential(\n    torch.nn.Conv2d(3,16,(5,5)),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d((2,2)),\n    torch.nn.Flatten()\n)\nnet2 = torch.nn.Sequential(\n    torch.nn.Linear(3136,10),\n)\nnet = torch.nn.Sequential(\n    net1, # 2d-part\n    net2, # 1d-part \n)\nloss_fn = torch.nn.CrossEntropyLoss()\nlrnr = fastai.learner.Learner(\n    dls=dls,\n    model=net,\n    loss_func=loss_fn,\n    #--#\n    metrics=[fastai.metrics.accuracy]\n)\n# Step3:\nlrnr.fit(10)\n# Step4: \nlrnr.model.to(\"cpu\")\nprint(f'train: {(lrnr.model(X).data.argmax(axis=1) == y).float().mean():.4f}')\nprint(f'val: {(lrnr.model(XX).data.argmax(axis=1) == yy).float().mean():.4f}')\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n1.592431\n1.526400\n0.457100\n00:01\n\n\n1\n1.417399\n1.401563\n0.505400\n00:01\n\n\n2\n1.346312\n1.337707\n0.530100\n00:01\n\n\n3\n1.289108\n1.314588\n0.537600\n00:00\n\n\n4\n1.251300\n1.248085\n0.561200\n00:01\n\n\n5\n1.217364\n1.244665\n0.565400\n00:01\n\n\n6\n1.189324\n1.224657\n0.570000\n00:01\n\n\n7\n1.164597\n1.191183\n0.583000\n00:01\n\n\n8\n1.140757\n1.186900\n0.585600\n00:00\n\n\n9\n1.117297\n1.169561\n0.596800\n00:00\n\n\n\n\n\n\ntrain: 0.6298\nval: 0.5968\n\n\n- shuffle 하나로 이렇게 상승한다고?"
  },
  {
    "objectID": "posts/DL_Summary3.html#c.-transferlearning",
    "href": "posts/DL_Summary3.html#c.-transferlearning",
    "title": "Deep Learning 3",
    "section": "C. TransferLearning",
    "text": "C. TransferLearning\n- 남들이 만들어놓은 좋은 model을 가져와서 써보자\n\nnet = torchvision.models.resnet18()\nnet\n\nResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=1000, bias=True)\n)\n\n\n- 마지막만 바꾸는 건 받아야하는 class의 개수가 원래 net과 다르니 이 부분을 바꿔준다\n\nnet.fc = torch.nn.Linear(512,10)\n\n\n# Step1:\nds1 = torch.utils.data.TensorDataset(X,y)\nds2 = torch.utils.data.TensorDataset(XX,yy)\ndl1 = torch.utils.data.DataLoader(ds1,batch_size=64,shuffle=True)\ndl2 = torch.utils.data.DataLoader(ds2,batch_size=100)\ndls = fastai.data.core.DataLoaders(dl1,dl2)\n# Step2:\nnet = torchvision.models.resnet18()\nnet.fc = torch.nn.Linear(512,10)\nloss_fn = torch.nn.CrossEntropyLoss()\nlrnr = fastai.learner.Learner(\n    dls=dls,\n    model=net,\n    loss_func=loss_fn,\n    #--#\n    metrics=[fastai.metrics.accuracy]\n)\n# Step3:\nlrnr.fit(10)\n# Step4: \n# 코랩사용시 아래는 주석처리할것 (이유: 코랩의 RAM이 충분하지 않음) valiation set의 accuracy는 fastai결과로 확인할것. \nlrnr.model.to(\"cpu\")\nprint(f'train: {(lrnr.model(X).data.argmax(axis=1) == y).float().mean():.4f}') # \nprint(f'val: {(lrnr.model(XX).data.argmax(axis=1) == yy).float().mean():.4f}')\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n1.187585\n1.287988\n0.556600\n00:11\n\n\n1\n0.948455\n0.954595\n0.673700\n00:11\n\n\n2\n0.800781\n1.140621\n0.629100\n00:11\n\n\n3\n0.673832\n0.857950\n0.709800\n00:11\n\n\n4\n0.604290\n1.005834\n0.677700\n00:11\n\n\n5\n0.497186\n0.754922\n0.747400\n00:10\n\n\n6\n0.415167\n0.770542\n0.756200\n00:11\n\n\n7\n0.349538\n0.815337\n0.758800\n00:11\n\n\n8\n0.290415\n1.048183\n0.722400\n00:11\n\n\n9\n0.242629\n0.965163\n0.742200\n00:11\n\n\n\n\n\n\ntrain: 0.9302\nval: 0.7421\n\n\n- 오버피팅이 좀 있지만 꽤 잘 맞춘다\n- 결론 : 남들이 쓰는 거 가져다가 살짝 바꿔서 쓰는 게 잘 나오긴 한다…\n! 의문점이 하나 생긴다. 과연 AI가 작동하는 방식을 하나하나 뜯어보면서 왜 이렇게 생각했는지 우리가 알 수 있을까?"
  },
  {
    "objectID": "posts/DL_Summary1.html",
    "href": "posts/DL_Summary1.html",
    "title": "Deep Learning 1",
    "section": "",
    "text": "1. Imports\n\nimport torch\nimport matplotlib.pyplot as plt \n\n\n\n2. RoadMap\n회귀분석 -&gt; 로지스틱 -&gt; 심층신경망(DNN) -&gt; 합성곱신경망(CNN)\n\n\n3. 회귀분석\n- 목적은 아래와 같이 데이터들에 잘 맞는 회귀선을 찾는 것\n\ntorch.manual_seed(21345)\nones= torch.ones(100).reshape(-1,1)\nx,_ = torch.randn(100).sort()\nx = x.reshape(-1,1)\nX = torch.concat([ones,x],axis=-1)\nW = torch.tensor([[2.5],[4]])\nϵ = torch.randn(100).reshape(-1,1)*0.5\ny = X@W + ϵ\n\n\nplt.plot(x,y,'o')\nplt.plot(x,2.5+4*x,'--')\n\n\n\n\n\n\n\n\n- 회귀모형에서 학습이란 위의 그림처럼 주황색 점선을 더 정확하게 추정하는 것\n\n\n4. 학습\n임의의 W값을 생각하자 그 다음 더 좋은 W값을 찾아서 업데이트 하면 되지 않을까?\n- Step1 Data\n데이터를 torch.tensor의 2차원 배열로 바꿔준다 .reshape(-1,1)을 사용 &lt;- 행렬계산을 해야하기에 2차원배열로 바꾸는 것\n- Step2 Update\n업데이트를 할 건데 뭘 어떻게 좋게 만들 것인지 기준을 잡아야한다. -&gt; Loss!(SSE)\n회귀직선이 정확할 수록 Loss가 작다.\n그렇다면 Loss값을 가장 작게 하는 W를 어떻게 찾을까?\nStep2-1 update의 정도를 파악하고 수정하는 과정\n\n임의의 점 \\(\\hat{w}\\) 를 찍는다.\n2.loss(W)의 기울기를 계산\n\\(\\hat{w}\\) - \\(\\alpha\\) \\(\\frac{d}{dW}loss(W)\\)\n\nStep2-2 \\(\\hat{w}\\) 수정\nWbefore = What.data\nWafter = What.data - \\(\\alpha\\) * What.grad\n- Step3 미분\nloss.backward()를 사용하면 What.grad()에 값이 생긴다. 곧 미분값\n- Step4 iteration\nfor문을 사용하여 반복학습 해준다\n\n\n각 Step의 변형\n- Step2의 변형\nMSELoss()를 이용한다.\n- Step1의 변형\nnet오브젝트를 이용하여 원활한 학습을 위한 데이터 정리를 해준다.\n- Step4의 변형\noptimizer 오브젝트를 이용하여 학습을 진행한다.\n\ntemp = [-2.4821, -2.3621, -1.9973, -1.6239, -1.4792, -1.4635, -1.4509, -1.4435,\n        -1.3722, -1.3079, -1.1904, -1.1092, -1.1054, -1.0875, -0.9469, -0.9319,\n        -0.8643, -0.7858, -0.7549, -0.7421, -0.6948, -0.6103, -0.5830, -0.5621,\n        -0.5506, -0.5058, -0.4806, -0.4738, -0.4710, -0.4676, -0.3874, -0.3719,\n        -0.3688, -0.3159, -0.2775, -0.2772, -0.2734, -0.2721, -0.2668, -0.2155,\n        -0.2000, -0.1816, -0.1708, -0.1565, -0.1448, -0.1361, -0.1057, -0.0603,\n        -0.0559, -0.0214,  0.0655,  0.0684,  0.1195,  0.1420,  0.1521,  0.1568,\n         0.2646,  0.2656,  0.3157,  0.3220,  0.3461,  0.3984,  0.4190,  0.5443,\n         0.5579,  0.5913,  0.6148,  0.6469,  0.6469,  0.6523,  0.6674,  0.7059,\n         0.7141,  0.7822,  0.8154,  0.8668,  0.9291,  0.9804,  0.9853,  0.9941,\n         1.0376,  1.0393,  1.0697,  1.1024,  1.1126,  1.1532,  1.2289,  1.3403,\n         1.3494,  1.4279,  1.4994,  1.5031,  1.5437,  1.6789,  2.0832,  2.2444,\n         2.3935,  2.6056,  2.6057,  2.6632]\nsales= [-8.5420, -6.5767, -5.9496, -4.4794, -4.2516, -3.1326, -4.0239, -4.1862,\n        -3.3403, -2.2027, -2.0262, -2.5619, -1.3353, -2.0466, -0.4664, -1.3513,\n        -1.6472, -0.1089, -0.3071, -0.6299, -0.0438,  0.4163,  0.4166, -0.0943,\n         0.2662,  0.4591,  0.8905,  0.8998,  0.6314,  1.3845,  0.8085,  1.2594,\n         1.1211,  1.9232,  1.0619,  1.3552,  2.1161,  1.1437,  1.6245,  1.7639,\n         1.6022,  1.7465,  0.9830,  1.7824,  2.1116,  2.8621,  2.1165,  1.5226,\n         2.5572,  2.8361,  3.3956,  2.0679,  2.8140,  3.4852,  3.6059,  2.5966,\n         2.8854,  3.9173,  3.6527,  4.1029,  4.3125,  3.4026,  3.2180,  4.5686,\n         4.3772,  4.3075,  4.4895,  4.4827,  5.3170,  5.4987,  5.4632,  6.0328,\n         5.2842,  5.0539,  5.4538,  6.0337,  5.7250,  5.7587,  6.2020,  6.5992,\n         6.4621,  6.5140,  6.6846,  7.3497,  8.0909,  7.0794,  6.8667,  7.4229,\n         7.2544,  7.1967,  9.5006,  9.0339,  7.4887,  9.0759, 11.0946, 10.3260,\n        12.2665, 13.0983, 12.5468, 13.8340]\nx = torch.tensor(temp).reshape(-1,1)\nones = torch.ones(100).reshape(-1,1)\nX = torch.concat([ones,x],axis=1)\ny = torch.tensor(sales).reshape(-1,1)\n\nnet = torch.nn.Linear(\n    in_features=2,\n    out_features=1,\n    bias=False\n)\nnet.weight.data = torch.tensor([[-5.0,  10.0]])\n\nloss_fn = torch.nn.MSELoss()\n\noptimizr = torch.optim.SGD(net.parameters(),lr=0.1)\nfor epoc in range(30):\n    # step1: yhat \n    yhat = net(X)\n    # step2: loss\n    loss = loss_fn(yhat,y)\n    # step3: 미분\n    loss.backward()\n    # step4: update\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o')\nplt.plot(x,yhat.data,'--')\nplt.title(f'net.weight={net.weight.data.reshape(-1)}');\n\n\n\n\n\n\n\n\n\n\n5. 로지스틱\n\nx = torch.tensor([-6,-5,-4,-3,-2,-1, 0, 1, 2, 3, 4, 5, 6.0]).reshape(-1,1)\ny = torch.tensor([ 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1]).reshape(-1,1)\nplt.plot(x,y,'o')\n\n\n\n\n\n\n\n\n- 위와 같은 범주형 문제는 이전의 문제처럼 회귀문제로 생각하는 건 쉽지 않아 보인다. 로지스틱으로 해볼까?\n우리가 예측하고 싶은 건 underlying이다.\n\nx = torch.linspace(-1,1,2000).reshape(2000,1)\nw0 = -1\nw1 = 5\nu = w0 + x*w1 # 선형변환이네?\nv = torch.exp(u) / (1+torch.exp(u)) \ny = torch.bernoulli(v)\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1, out_features=1),\n    torch.nn.Sigmoid()\n)\nl1, a1 = net # 네트워크는 섭스크립터블 오브젝트이니까..\nl1.weight.data = torch.tensor([[-0.3]])\nl1.bias.data = torch.tensor([-0.8])\n#loss_fn = torch.nn.MSELoss() # -- 이 코드 일단 쓰지 않을게여\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25)\n#---#\nfor epoc in range(100):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = torch.mean((y-yhat)**2)\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.05)\nplt.plot(x,v,'--r')\nplt.plot(x,yhat.data,'--b')\nplt.title('after 100 epochs')\n\nText(0.5, 1.0, 'after 100 epochs')\n\n\n\n\n\n\n\n\n\n5000번 학습하면?\n\nx = torch.linspace(-1,1,2000).reshape(2000,1)\nw0 = -1\nw1 = 5\nu = w0 + x*w1 # 선형변환이네?\nv = torch.exp(u) / (1+torch.exp(u)) \ny = torch.bernoulli(v)\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1, out_features=1),\n    torch.nn.Sigmoid()\n)\nl1, a1 = net # 네트워크는 섭스크립터블 오브젝트이니까..\nl1.weight.data = torch.tensor([[-0.3]])\nl1.bias.data = torch.tensor([-0.8])\n#loss_fn = torch.nn.MSELoss() # -- 이 코드 일단 쓰지 않을게여\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25)\n#---#\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = torch.mean((y-yhat)**2)\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.05)\nplt.plot(x,v,'--r')\nplt.plot(x,yhat.data,'--b')\nplt.title('after 100 epochs')\n\nText(0.5, 1.0, 'after 100 epochs')\n\n\n\n\n\n\n\n\n\n그런데 우리가 초기값을 -0.8,-0.3 으로 운 좋게 잘 잡아서 적합이 이렇게 잘 된 거 아닐까?\n안 좋은 초기값을 잡으면 어떻게 될까? 그래도 적합 시켜줄까?\n\nimport torch\nimport matplotlib.pyplot as plt \nimport numpy as np\nimport pandas as pd\n\ndef plot_loss(loss_fn, ax=None, Wstar=[-1,5]):\n    w0hat,w1hat =torch.meshgrid(torch.arange(-10,3,0.1),torch.arange(-1,10,0.1),indexing='ij')\n    w0hat = w0hat.reshape(-1)\n    w1hat = w1hat.reshape(-1)\n    def l(w0hat,w1hat):\n        yhat = torch.exp(w0hat+w1hat*x)/(1+torch.exp(w0hat+w1hat*x))\n        return loss_fn(yhat,y) \n    loss = list(map(l,w0hat,w1hat))\n    #---#\n    if ax is None: \n        fig = plt.figure()\n        ax = fig.add_subplot(1,1,1,projection='3d')\n    ax.scatter(w0hat,w1hat,loss,s=0.001) \n    ax.scatter(w0hat[::20],w1hat[::20],loss[::20],s=0.1,color='C0') \n    w0star,w1star = np.array(Wstar).reshape(-1)\n    ax.scatter(w0star,w1star,l(w0star,w1star),s=200,marker='*',color='red',label=f\"W=[{w0star:.1f},{w1star:.1f}]\")\n    #---#\n    ax.elev = 15\n    ax.dist = -20\n    ax.azim = 75    \n    ax.legend()\n    ax.set_xlabel(r'$w_0$')  # x축 레이블 설정\n    ax.set_ylabel(r'$w_1$')  # y축 레이블 설정\n    ax.set_xticks([-10,-5,0])  # x축 틱 간격 설정\n    ax.set_yticks([-10,0,10])  # y축 틱 간격 설정\n\n\ndef learn_and_record(net, loss_fn, optimizr):\n    yhat_history = [] \n    loss_history = []\n    What_history = []\n    Whatgrad_history = []\n    What_history.append([net[0].bias.data.item(), net[0].weight.data.item()])\n    for epoc in range(100): \n        ## step1 \n        yhat = net(x)\n        ## step2 \n        loss = loss_fn(yhat,y)\n        ## step3\n        loss.backward() \n        ## step4 \n        optimizr.step()\n        ## record \n        if epoc % 5 ==0: \n            yhat_history.append(yhat.reshape(-1).data.tolist())\n            loss_history.append(loss.item())\n            What_history.append([net[0].bias.data.item(), net[0].weight.data.item()])\n            Whatgrad_history.append([net[0].bias.grad.item(), net[0].weight.grad.item()])\n        optimizr.zero_grad() \n        \n    return yhat_history, loss_history, What_history, Whatgrad_history\n\n\ndef show_animation(net, loss_fn, optimizr):\n    yhat_history,loss_history,What_history,Whatgrad_history = learn_and_record(net,loss_fn,optimizr)\n    \n    fig = plt.figure(figsize=(7.5,3.5))\n    ax1 = fig.add_subplot(1, 2, 1)\n    ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n    ## ax1: 왼쪽그림 \n    ax1.scatter(x,y,alpha=0.01)\n    ax1.scatter(x[0],y[0],color='C0',label=r\"observed data = $(x_i,y_i)$\")\n    ax1.plot(x,v,'--',label=r\"prob (true) = $(x_i,\\frac{exp(-1+5x_i)}{1+exp(-1+5x_i)})$\")    \n    line, = ax1.plot(x,yhat_history[0],'--',label=r\"prob (estimated) = $(x_i,\\hat{y}_i)$\") \n    ax1.legend()\n    ## ax2: 오른쪽그림 \n    plot_loss(loss_fn,ax2)\n    ax2.scatter(np.array(What_history)[0,0],np.array(What_history)[0,1],loss_history[0],color='blue',s=200,marker='*')    \n    def animate(epoc):\n        line.set_ydata(yhat_history[epoc])\n        w0hat = np.array(What_history)[epoc,0]\n        w1hat = np.array(What_history)[epoc,1]\n        w0hatgrad = np.array(Whatgrad_history)[epoc,0]\n        w1hatgrad = np.array(Whatgrad_history)[epoc,1]\n        ax2.scatter(w0hat,w1hat,loss_history[epoc],color='grey')\n        ax2.set_title(f\"What.grad=[{w0hatgrad:.4f},{w1hatgrad:.4f}]\",y=0.8)\n        fig.suptitle(f\"epoch={epoc*5} // What=[{w0hat:.2f},{w1hat:.2f}] // Loss={loss_fn.__class__.__name__} // Opt={optimizr.__class__.__name__}\")\n        return line\n    ani = animation.FuncAnimation(fig, animate, frames=20)    \n    plt.close()\n    return ani\n\n- 좋은 초기값\n\nfrom matplotlib import animation\nplt.rcParams[\"animation.html\"] = \"jshtml\"\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-0.8])\nnet[0].weight.data = torch.tensor([[-0.3]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- 최악의 초기값\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-10.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- 해결 접근법\n컴공 : 에폭을 늘릴까?\n산공 : 옵티마이저를 바꿀까?\n통계 : Loss를 바꿀까?\n\n\n손실함수의 개선\nLoss 중 BCELoss라는 것이 있는데 이것은 반복을 했을 때 원하는 만큼 움직이지 않는다면 가속도를 붙혀서 그 다음 반복시에는 더 많이 움직이게끔 방식이다.\n여기서 움직이게 한다는 건 Loss를 줄여서 적합을 시킨다는 의미이다.\n사용방법은 loss를 선언할 때 BCELoss() 라고 쓰면 된다\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1, out_features=1),\n    torch.nn.Sigmoid()\n)\nl1, a1 = net # 네트워크는 섭스크립터블 오브젝트이니까..\nl1.weight.data = torch.tensor([[-0.3]])\nl1.bias.data = torch.tensor([-0.8])\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25)\n#---#\nfor epoc in range(100):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y) # yhat부터 써야함\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.05)\nplt.plot(x,v,'--r')\nplt.plot(x,yhat.data,'--b')\nplt.title('after 100 epochs')\n\nText(0.5, 1.0, 'after 100 epochs')\n\n\n\n\n\n\n\n\n\n- MSELoss를 사용할 때보다 BCELoss를 사용했을 때 훨씬 더 적합이 되는 듯한 느낌이다.\n\nfig = plt.figure()\nax1 = fig.add_subplot(1,2,1,projection='3d')\nax2 = fig.add_subplot(1,2,2,projection='3d')\nplot_loss(torch.nn.MSELoss(),ax1)\nplot_loss(torch.nn.BCELoss(),ax2)\n\n\n\n\n\n\n\n\n뭔가 더 잘 떨어지게끔 오른쪽이 미끄럼틀같이 펴져있다.\n- MSELoss\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-0.8])\nnet[0].weight.data = torch.tensor([[-0.3]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- BCELoss\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-0.8])\nnet[0].weight.data = torch.tensor([[-0.3]])\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\n옵티마이저의 개선\n국민옵티마이저 Adam이 있다. 웬만하면 이거 쓰면 된다.\n- MSELoss + SGD\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-10.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.05) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n꿈쩍도 하지 않는 모습…\n- MSELoss + Adam\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-10.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n너무나도 뚝뚝 잘 내려온다\n- 그럼 BCELoss + Adam 쓰면 무적인가?\n\n\n6.로지스틱의 한계\n중소·지방 기업 “뽑아봤자 그만두니까”\n중소기업 관계자들은 고스펙 지원자를 꺼리는 이유로 높은 퇴직률을 꼽는다. 여건이 좋은 대기업으로 이직하거나 회사를 관두는 경우가 많다는 하소연이다. 고용정보원이 지난 3일 공개한 자료에 따르면 중소기업 청년취업자 가운데 49.5%가 2년 내에 회사를 그만두는 것으로 나타났다.\n중소 IT업체 관계자는 “기업 입장에서 가장 뼈아픈 게 신입사원이 그만둬서 새로 뽑는 일”이라며 “명문대 나온 스펙 좋은 지원자를 뽑아놔도 1년을 채우지 않고 그만두는 사원이 대부분이라 우리도 눈을 낮춰 사람을 뽑는다”고 말했다.\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/guebin/DL2024/main/posts/dnnex.csv\")\nx = torch.tensor(df.x).float().reshape(-1,1)\ny = torch.tensor(df.y).float().reshape(-1,1)\nprob = torch.tensor(df.prob).float().reshape(-1,1)\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(x[0],y[0],'o',label= r\"observed data = $(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,prob,'--b',label= r\"prob (true, unknown)\")\nplt.legend()\n\n\n\n\n\n\n\n\n- 이런 꺾인 선은 로지스틱으로 적합하기 힘들어…\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---# \nfor epoc in range(5000):\n    ## 1 \n    yhat = net(x)\n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(x[0],y[0],'o',label= r\"observed data = $(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,prob,'--b',label= r\"prob (true, unknown)\")\nplt.plot(x,net(x).data, '--', label= r\"prob (estimated) = $(x_i,\\hat{y}_i)$\")\nplt.legend()\n\n\n\n\n\n\n\n\n\n\n7.로지스틱의 한계 극복\nReLU : 음수인 것은 0으로 만들고 양수는 그대로 둔다. 그럼 그래프가 꺾인다.\n\ny = x*0 \ny[x&lt;0] = (9*x+4.5)[x&lt;0]\ny[x&gt;0] = (-4.5*x+4.5)[x&gt;0]\n\nplt.plot(y,'--')\n\n\n\n\n\n\n\n\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/guebin/DL2024/main/posts/dnnex.csv\")\nx = torch.tensor(df.x).float().reshape(-1,1)\ny = torch.tensor(df.y).float().reshape(-1,1)\nprob = torch.tensor(df.prob).float().reshape(-1,1)\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,2),\n    torch.nn.ReLU(),\n    torch.nn.Linear(2,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(3000):\n    ## \n    yhat = net(x)\n    ## \n    loss = loss_fn(yhat,y)\n    ## \n    loss.backward()\n    ## \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(x[0],y[0],'o',label= r\"observed data = $(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,prob,'--b',label= r\"prob (true, unknown)\")\nplt.plot(x,net(x).data,'--',label=\"prob (estimated) -- after 3000 epochs\")\nplt.legend()\n\n\n\n\n\n\n\n\n\nfor epoc in range(3000):\n    ## \n    yhat = net(x)\n    ## \n    loss = loss_fn(yhat,y)\n    ## \n    loss.backward()\n    ## \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(x[0],y[0],'o',label= r\"observed data = $(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,prob,'--b',label= r\"prob (true, unknown)\")\nplt.plot(x,net(x).data,'--',label=\"prob (estimated) -- after 6000 epochs\")\nplt.legend()\n\n\n\n\n\n\n\n\nReLU에 대해서는 깊게 알기보단 그래프를 꺾을 수 있다\n그 꺾는다는 의미는 표현력을 높인다고 생각하는 것이 좋다.\n로지스틱의 한계를 마주했을 때 그저 증가함수는 표현을 못 하는 그래프들이 있기때문에 문제였는데\n이제 ReLU를 이용해서 꺾인 선 그래프도 그릴 수 있게 되었고 그것으로 적합해서 맞춰나가면 해결할 수 있게 되었다.\n즉 그래프의 표현력이 늘었다. 그렇다면 모든 그래프도 적합할 수 있을 거 같은데?\n\ntorch.manual_seed(21345)\nx = torch.linspace(0,2,2000).reshape(-1,1)\neps = torch.randn(2000).reshape(-1,1)*0.05\nfx = torch.exp(-1*x)* torch.abs(torch.cos(3*x))*(torch.sin(3*x))\ny = fx + eps\n\nplt.plot(x,y,label=r\"observed data (with error): $(x_i,y_i)$\", alpha=0.2)\nplt.plot(x,fx,'--',color=\"C0\",label=r\"underlying (true, unknown): $e^{-x}|\\cos(3x)|\\sin(3x)$\")\nplt.legend()\n\n\n\n\n\n\n\n\n위의 문제는 로지스틱이 아니라 회귀선을 맞춰보는 느낌이 강하기에 MSELoss를 사용\n\n#torch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1024),\n    torch.nn.ReLU(),\n    torch.nn.Linear(1024,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#--#\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x)\n    ## 2\n    loss = loss_fn(yhat,y)\n    ## 3\n    loss.backward()\n    ## 4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,label=r\"observed data: $(x_i,y_i)$\", alpha=0.2)\nplt.plot(x,fx,'--',color=\"C0\",label=r\"underlying (true, unkown): $e^{-x}|\\cos(3x)|\\sin(3x)$\")\nplt.plot(x,yhat.data,'--',color=\"C1\",label=r\"underlying (esimated): $(x_i,\\hat{y}_i)$\")\nplt.legend()\n\n\n\n\n\n\n\n\n- 이렇게 복잡한 것도 잘 맞춰준다.\n\n\n8. 그럼 무적인가? (시벤코정리)\n치명적인 문제 : Overfiiting\n표현력은 무한하지만 오차까지 적합해버리는 문제가 있다\n이러한 문제를 해결하기 위해 드랍아웃이라는 기법이 존재함\n\nu = torch.randn(20).reshape(10,2)\nu\n\ntensor([[ 0.9303, -1.4108],\n        [ 0.1033,  0.3010],\n        [-0.3732,  2.3353],\n        [ 0.2152,  0.1908],\n        [-0.1696,  1.1762],\n        [-1.4862, -0.0343],\n        [-0.8385,  0.3719],\n        [ 0.9422,  0.9081],\n        [-1.3018, -0.7977],\n        [ 0.1008,  0.2014]])\n\n\n\nd = torch.nn.Dropout(0.9)\nd(u)\n\ntensor([[ 0.0000, -0.0000],\n        [ 1.0332,  0.0000],\n        [-0.0000,  0.0000],\n        [ 0.0000,  0.0000],\n        [-1.6961,  0.0000],\n        [-0.0000, -0.0000],\n        [-8.3853,  0.0000],\n        [ 0.0000,  0.0000],\n        [-0.0000, -0.0000],\n        [ 0.0000,  2.0141]])\n\n\n- 드랍아웃\n90%의 드랍아웃: 드랍아웃층의 입력 중 임의로 90%를 골라서 결과를 0으로 만든다. + 그리고 0이 되지않고 살아남은 값들은 10배 만큼 값이 커진다.\n의미: each iteration (each epoch x) 마다 학습에 참여하는 노드가 랜덤으로 결정됨.\n느낌: 모든 노드가 골고루 학습가능 + 한 두개의 특화된 능력치가 개발되기 보다 평균적인 능력치가 전반적으로 개선됨\n배깅과 랜덤포레스트의 느낌으로 오버피팅을 해결함"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": ".",
    "section": "",
    "text": "Deep Learning 4\n\n\n\n\n\n\n\n\n\n\n\nApr 19, 2024\n\n\n차상진\n\n\n\n\n\n\n\n\n\n\n\n\nDeep Learning 3\n\n\n\n\n\n\n\n\n\n\n\nApr 18, 2024\n\n\n차상진\n\n\n\n\n\n\n\n\n\n\n\n\nDeep Learning 2\n\n\n\n\n\n\n\n\n\n\n\nApr 9, 2024\n\n\n차상진\n\n\n\n\n\n\n\n\n\n\n\n\nDeep Learning 1\n\n\n\n\n\n\n\n\n\n\n\nApr 8, 2024\n\n\n차상진\n\n\n\n\n\n\nNo matching items"
  }
]