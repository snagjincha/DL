{
 "cells": [
  {
   "cell_type": "raw",
   "id": "795bb849-a21e-457a-a6e7-71d32bb7c593",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Deep Learning 10\"\n",
    "author: \"차상진\"\n",
    "date: \"2024-06-02\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46da08c8-c6b7-4c8b-9fe4-0410f2cf0f46",
   "metadata": {},
   "source": [
    "# **1. Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "51cc079d-2ac8-43d1-9e73-274c0a67a203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f81e84-ea6b-4ecd-af1f-f4133e527fa7",
   "metadata": {},
   "source": [
    "# **2. Game1 : `Bandit`게임**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbbc177-71db-422e-9258-85dc28ea1d54",
   "metadata": {},
   "source": [
    "## **A. 게임설명 및 원시코드**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141ad906-d2e1-46f8-8320-b66a5363d66c",
   "metadata": {},
   "source": [
    "`-` 버튼0 -> 1의 보상 , 버튼2 -> 10의 보상"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dfabcb-9913-4e57-aa0c-76924de38a79",
   "metadata": {},
   "source": [
    "`-` 처음에는 아는 것이 없으니 아무거나 눌러봐야겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc69ee08-4934-4278-bc85-9a7f66297566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_space = [0,1]\n",
    "action = np.random.choice(action_space)\n",
    "action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84424c78-b5e8-4032-a4ee-fb20f21b6798",
   "metadata": {},
   "source": [
    "- `action_space`와 `action`이라는 용어를 기억"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295730fc-1609-4002-9f6c-50db99fc70a1",
   "metadata": {},
   "source": [
    "`-` 버튼을 누른 행위에 대한 보상 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "56c0f2f1-b9e8-47a3-8606-7fbfade329f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward = 1 if action == 0 else 10\n",
    "reward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ddd2a6-2319-4e7b-ac2e-c39406f6c6db",
   "metadata": {},
   "source": [
    "`-` 아무 버튼이나 10번 눌러보며 데이터 쌓기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eff8ed3c-3659-446c-ab65-4ef841345c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 10\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "1 10\n",
      "0 1\n",
      "0 1\n",
      "1 10\n",
      "0 1\n",
      "1 10\n"
     ]
    }
   ],
   "source": [
    "action_space = [0,1]\n",
    "for l in range(10):\n",
    "    action = np.random.choice(action_space)\n",
    "    reward = 1 if action == 0 else 10\n",
    "    print(action , reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd72649c-73e9-45f1-a515-695db34f1912",
   "metadata": {},
   "source": [
    "`-` 사람이라면 1을 눌러야겠다는 생각을 함. 그런데 컴퓨터가 이렇게 생각하게 어떻게 만들지? 생각하는 과정을 연구한 것이 강화학습이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5bad27ee-f2e1-4fd3-9d0a-1fe655949efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "버튼1 10\n",
      "버튼1 10\n",
      "버튼1 10\n",
      "버튼1 10\n",
      "버튼1 10\n",
      "버튼1 10\n",
      "버튼1 10\n",
      "버튼1 10\n",
      "버튼1 10\n",
      "버튼1 10\n"
     ]
    }
   ],
   "source": [
    "# 꺠달은 사람\n",
    "action_space = ['버튼0','버튼1']\n",
    "for _ in range(10):\n",
    "    action = '버튼1'\n",
    "    reward = 1 if action == \"버튼0\" else 10\n",
    "    print(action,reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932233dd-5695-44a0-a248-242c82219ce3",
   "metadata": {},
   "source": [
    "`-` 강화학습 : 환경(enviornment)를 이해 -> 에이전트(agent)가 행동(action)을 결정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a183b1-2d06-4ced-b3cd-7100f189d25a",
   "metadata": {},
   "source": [
    "- 게임클리어조건: (1) 20번은 그냥 진행 (2) 최근 20번의 보상의 평균이 9.5점 이상이면 게임이 클리어 되었다고 생각하자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd75c2f-318a-45b5-95af-60708b6190dc",
   "metadata": {},
   "source": [
    "`-` 원시코드1 : 환경을 이해하지 못한 에이전트 - 게임 클리어 불가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2163a891-4f47-4360-b789-68658dcad667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시도:1\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:2\t행동:0\t보상:1\t최근20번보상평균:5.5000\t\n",
      "시도:3\t행동:1\t보상:10\t최근20번보상평균:7.0000\t\n",
      "시도:4\t행동:0\t보상:1\t최근20번보상평균:5.5000\t\n",
      "시도:5\t행동:0\t보상:1\t최근20번보상평균:4.6000\t\n",
      "시도:6\t행동:1\t보상:10\t최근20번보상평균:5.5000\t\n",
      "시도:7\t행동:0\t보상:1\t최근20번보상평균:4.8571\t\n",
      "시도:8\t행동:0\t보상:1\t최근20번보상평균:4.3750\t\n",
      "시도:9\t행동:0\t보상:1\t최근20번보상평균:4.0000\t\n",
      "시도:10\t행동:1\t보상:10\t최근20번보상평균:4.6000\t\n",
      "시도:11\t행동:0\t보상:1\t최근20번보상평균:4.2727\t\n",
      "시도:12\t행동:0\t보상:1\t최근20번보상평균:4.0000\t\n",
      "시도:13\t행동:0\t보상:1\t최근20번보상평균:3.7692\t\n",
      "시도:14\t행동:0\t보상:1\t최근20번보상평균:3.5714\t\n",
      "시도:15\t행동:0\t보상:1\t최근20번보상평균:3.4000\t\n",
      "시도:16\t행동:1\t보상:10\t최근20번보상평균:3.8125\t\n",
      "시도:17\t행동:0\t보상:1\t최근20번보상평균:3.6471\t\n",
      "시도:18\t행동:0\t보상:1\t최근20번보상평균:3.5000\t\n",
      "시도:19\t행동:0\t보상:1\t최근20번보상평균:3.3684\t\n",
      "시도:20\t행동:1\t보상:10\t최근20번보상평균:3.7000\t\n",
      "--\n",
      "시도:21\t행동:1\t보상:10\t최근20번보상평균:3.7000\t\n",
      "시도:22\t행동:0\t보상:1\t최근20번보상평균:3.7000\t\n",
      "시도:23\t행동:1\t보상:10\t최근20번보상평균:3.7000\t\n",
      "시도:24\t행동:0\t보상:1\t최근20번보상평균:3.7000\t\n",
      "시도:25\t행동:0\t보상:1\t최근20번보상평균:3.7000\t\n",
      "시도:26\t행동:0\t보상:1\t최근20번보상평균:3.2500\t\n",
      "시도:27\t행동:0\t보상:1\t최근20번보상평균:3.2500\t\n",
      "시도:28\t행동:0\t보상:1\t최근20번보상평균:3.2500\t\n",
      "시도:29\t행동:1\t보상:10\t최근20번보상평균:3.7000\t\n",
      "시도:30\t행동:1\t보상:10\t최근20번보상평균:3.7000\t\n",
      "시도:31\t행동:1\t보상:10\t최근20번보상평균:4.1500\t\n",
      "시도:32\t행동:0\t보상:1\t최근20번보상평균:4.1500\t\n",
      "시도:33\t행동:0\t보상:1\t최근20번보상평균:4.1500\t\n",
      "시도:34\t행동:0\t보상:1\t최근20번보상평균:4.1500\t\n",
      "시도:35\t행동:1\t보상:10\t최근20번보상평균:4.6000\t\n",
      "시도:36\t행동:0\t보상:1\t최근20번보상평균:4.1500\t\n",
      "시도:37\t행동:1\t보상:10\t최근20번보상평균:4.6000\t\n",
      "시도:38\t행동:1\t보상:10\t최근20번보상평균:5.0500\t\n",
      "시도:39\t행동:0\t보상:1\t최근20번보상평균:5.0500\t\n",
      "시도:40\t행동:0\t보상:1\t최근20번보상평균:4.6000\t\n",
      "시도:41\t행동:0\t보상:1\t최근20번보상평균:4.1500\t\n",
      "시도:42\t행동:0\t보상:1\t최근20번보상평균:4.1500\t\n",
      "시도:43\t행동:0\t보상:1\t최근20번보상평균:3.7000\t\n",
      "시도:44\t행동:0\t보상:1\t최근20번보상평균:3.7000\t\n",
      "시도:45\t행동:1\t보상:10\t최근20번보상평균:4.1500\t\n",
      "시도:46\t행동:0\t보상:1\t최근20번보상평균:4.1500\t\n",
      "시도:47\t행동:0\t보상:1\t최근20번보상평균:4.1500\t\n",
      "시도:48\t행동:1\t보상:10\t최근20번보상평균:4.6000\t\n",
      "시도:49\t행동:1\t보상:10\t최근20번보상평균:4.6000\t\n",
      "시도:50\t행동:0\t보상:1\t최근20번보상평균:4.1500\t\n"
     ]
    }
   ],
   "source": [
    "action_space = [0,1]\n",
    "actions = []\n",
    "rewards = []\n",
    "for t in range(1,51):\n",
    "    action = np.random.choice(action_space)\n",
    "    reward = 1 if action == 0 else 10\n",
    "    actions.append(action)\n",
    "    rewards.append(reward)\n",
    "\n",
    "    print(\n",
    "        f\"시도:{t}\\t\"\n",
    "        f\"행동:{action}\\t\"\n",
    "        f\"보상:{reward}\\t\"\n",
    "        f\"최근20번보상평균:{np.mean(rewards[-20:]):.4f}\\t\"\n",
    "    )\n",
    "\n",
    "    if t<20:\n",
    "        pass\n",
    "    elif t==20:\n",
    "        print('--')\n",
    "    else:\n",
    "        if np.mean(rewards[-20:]) > 9.5:\n",
    "            print('Game Clear')\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd155b5-b766-4606-bc00-1aafdf5c892b",
   "metadata": {},
   "source": [
    "`-` 원시코드2 : 환경을 깨달은 에이전트 - 게임 클리어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0a71d594-a571-4154-9987-b77c4d77707c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시도:1\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:2\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:3\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:4\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:5\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:6\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:7\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:8\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:9\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:10\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:11\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:12\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:13\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:14\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:15\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:16\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:17\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:18\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:19\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:20\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "--\n",
      "시도:21\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "Game Clear\n"
     ]
    }
   ],
   "source": [
    "action_space = [0,1]\n",
    "actions = []\n",
    "rewards = []\n",
    "for t in range(1,51):\n",
    "    action = 1\n",
    "    reward = 1 if action == 0 else 10\n",
    "    actions.append(action)\n",
    "    rewards.append(reward)\n",
    "\n",
    "    print(\n",
    "        f\"시도:{t}\\t\"\n",
    "        f\"행동:{action}\\t\"\n",
    "        f\"보상:{reward}\\t\"\n",
    "        f\"최근20번보상평균:{np.mean(rewards[-20:]):.4f}\\t\"\n",
    "    )\n",
    "\n",
    "    if t<20:\n",
    "        pass\n",
    "    elif t==20:\n",
    "        print('--')\n",
    "    else:\n",
    "        if np.mean(rewards[-20:]) > 9.5:\n",
    "            print('Game Clear')\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312d5ba3-6755-45d5-9784-08f09ba23781",
   "metadata": {},
   "source": [
    "## **B. 수정1 : `Env`구현**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dcc7e4-4fbe-48ba-9565-74a9b4e9b0da",
   "metadata": {},
   "source": [
    "`-` Bandit 클래스 선언 + `.step()`구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0e1d0bd6-633f-4546-87aa-e27123c69a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bandit:\n",
    "    def step(self,agent_action):\n",
    "        reward = 1 if agent_action == 0 else 10\n",
    "        return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c1d484d0-2458-4dba-8010-f3891cb271a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시도:1\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:2\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:3\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:4\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:5\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:6\t행동:0\t보상:1\t최근20번보상평균:8.5000\t\n",
      "시도:7\t행동:0\t보상:1\t최근20번보상평균:7.4286\t\n",
      "시도:8\t행동:0\t보상:1\t최근20번보상평균:6.6250\t\n",
      "시도:9\t행동:1\t보상:10\t최근20번보상평균:7.0000\t\n",
      "시도:10\t행동:0\t보상:1\t최근20번보상평균:6.4000\t\n",
      "시도:11\t행동:1\t보상:10\t최근20번보상평균:6.7273\t\n",
      "시도:12\t행동:0\t보상:1\t최근20번보상평균:6.2500\t\n",
      "시도:13\t행동:1\t보상:10\t최근20번보상평균:6.5385\t\n",
      "시도:14\t행동:0\t보상:1\t최근20번보상평균:6.1429\t\n",
      "시도:15\t행동:1\t보상:10\t최근20번보상평균:6.4000\t\n",
      "시도:16\t행동:0\t보상:1\t최근20번보상평균:6.0625\t\n",
      "시도:17\t행동:1\t보상:10\t최근20번보상평균:6.2941\t\n",
      "시도:18\t행동:1\t보상:10\t최근20번보상평균:6.5000\t\n",
      "시도:19\t행동:0\t보상:1\t최근20번보상평균:6.2105\t\n",
      "시도:20\t행동:0\t보상:1\t최근20번보상평균:5.9500\t\n",
      "--\n",
      "시도:21\t행동:1\t보상:10\t최근20번보상평균:5.9500\t\n",
      "시도:22\t행동:1\t보상:10\t최근20번보상평균:5.9500\t\n",
      "시도:23\t행동:1\t보상:10\t최근20번보상평균:5.9500\t\n",
      "시도:24\t행동:0\t보상:1\t최근20번보상평균:5.5000\t\n",
      "시도:25\t행동:1\t보상:10\t최근20번보상평균:5.5000\t\n",
      "시도:26\t행동:0\t보상:1\t최근20번보상평균:5.5000\t\n",
      "시도:27\t행동:1\t보상:10\t최근20번보상평균:5.9500\t\n",
      "시도:28\t행동:0\t보상:1\t최근20번보상평균:5.9500\t\n",
      "시도:29\t행동:1\t보상:10\t최근20번보상평균:5.9500\t\n",
      "시도:30\t행동:0\t보상:1\t최근20번보상평균:5.9500\t\n",
      "시도:31\t행동:1\t보상:10\t최근20번보상평균:5.9500\t\n",
      "시도:32\t행동:1\t보상:10\t최근20번보상평균:6.4000\t\n",
      "시도:33\t행동:1\t보상:10\t최근20번보상평균:6.4000\t\n",
      "시도:34\t행동:0\t보상:1\t최근20번보상평균:6.4000\t\n",
      "시도:35\t행동:0\t보상:1\t최근20번보상평균:5.9500\t\n",
      "시도:36\t행동:1\t보상:10\t최근20번보상평균:6.4000\t\n",
      "시도:37\t행동:1\t보상:10\t최근20번보상평균:6.4000\t\n",
      "시도:38\t행동:1\t보상:10\t최근20번보상평균:6.4000\t\n",
      "시도:39\t행동:0\t보상:1\t최근20번보상평균:6.4000\t\n",
      "시도:40\t행동:0\t보상:1\t최근20번보상평균:6.4000\t\n",
      "시도:41\t행동:0\t보상:1\t최근20번보상평균:5.9500\t\n",
      "시도:42\t행동:0\t보상:1\t최근20번보상평균:5.5000\t\n",
      "시도:43\t행동:1\t보상:10\t최근20번보상평균:5.5000\t\n",
      "시도:44\t행동:1\t보상:10\t최근20번보상평균:5.9500\t\n",
      "시도:45\t행동:1\t보상:10\t최근20번보상평균:5.9500\t\n",
      "시도:46\t행동:0\t보상:1\t최근20번보상평균:5.9500\t\n",
      "시도:47\t행동:0\t보상:1\t최근20번보상평균:5.5000\t\n",
      "시도:48\t행동:0\t보상:1\t최근20번보상평균:5.5000\t\n",
      "시도:49\t행동:0\t보상:1\t최근20번보상평균:5.0500\t\n",
      "시도:50\t행동:0\t보상:1\t최근20번보상평균:5.0500\t\n"
     ]
    }
   ],
   "source": [
    "env = Bandit()\n",
    "action_space = [0,1]\n",
    "actions = []\n",
    "rewards = []\n",
    "for t in range(1,51):\n",
    "    action = np.random.choice(action_space)\n",
    "    reward = env.step(action)\n",
    "    actions.append(action)\n",
    "    rewards.append(reward)\n",
    "\n",
    "    print(\n",
    "        f\"시도:{t}\\t\"\n",
    "        f\"행동:{action}\\t\"\n",
    "        f\"보상:{reward}\\t\"\n",
    "        f\"최근20번보상평균:{np.mean(rewards[-20:]):.4f}\\t\"\n",
    "    )\n",
    "    if t<20:\n",
    "        pass \n",
    "    elif t==20:\n",
    "        print(\"--\")\n",
    "    else: \n",
    "        if np.mean(rewards[-20:]) > 9.5:\n",
    "            print(\"Game Clear\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6eb9e7-2efd-4600-8ad8-94a1807974b7",
   "metadata": {},
   "source": [
    "## **C. 수정2 : `Agent`구현 (인간지능)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c49db9-6ff4-4d5b-bcb5-db25a8fe4353",
   "metadata": {},
   "source": [
    "`-` Agent 클래스 설계"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37339fe0-f0ae-4f53-8917-2e940bee920c",
   "metadata": {},
   "source": [
    "- 액션을 하고, 본인의 행동과 환경에서 받은 reward를 기억\n",
    "- `.act()`함수와 `.save_experience()`함수 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a31a48d7-e611-4e7f-b65a-3a94819565ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self):\n",
    "        self.action_space = [0,1]\n",
    "        self.action = None\n",
    "        self.reward = None\n",
    "        self.actions = []\n",
    "        self.rewards = []\n",
    "    def act(self):\n",
    "        self.action = 1\n",
    "    def save_experience(self):\n",
    "        self.actions.append(self.action)\n",
    "        self.rewards.append(self.reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f28eb3a-d5fe-4964-b470-1c27b6d14fde",
   "metadata": {},
   "source": [
    "시점0 : init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "801a3838-62bb-4e43-9da8-584041b8f67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent()\n",
    "env = Bandit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5b107e69-da0a-497c-afec-f37be2dac51a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None, [], [])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.action, agent.reward, agent.actions, agent.rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fab4e3-a256-4ad6-8792-92628c919dea",
   "metadata": {},
   "source": [
    "시점1 : agent가 action을 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c2cead6e-f394-447c-826e-4d79fdcd3da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.act()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "850e83a7-5197-4b9b-b3e5-579d32ff1fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, None, [], [])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.action, agent.reward, agent.actions, agent.rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac8fd6c-4a65-4515-8a11-aa3a4dfd94c8",
   "metadata": {},
   "source": [
    "시점2: env가 agent에게 보상을 줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4c9e92a4-9afe-4cf6-8199-7c729b17b4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.reward = env.step(agent.action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "94069d0b-138e-4e1b-8f3d-a66071dea557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10, [], [])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.action, agent.reward, agent.actions, agent.rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe67235-b7ee-48ad-b5d6-904a1ffc2c46",
   "metadata": {},
   "source": [
    "시점3: 경험을 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e8ac01a0-2d03-4b23-b809-63d876088d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.save_experience()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6220d9eb-8492-4fa5-b3a9-2d56380775f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10, [1], [10])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.action, agent.reward, agent.actions, agent.rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9feb2a-fad9-482b-b1f4-7d8a5b25b9ab",
   "metadata": {},
   "source": [
    "-전체코드-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5f67c2dc-ddc1-43ad-af35-d6263c5efaf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시도:1\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:2\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:3\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:4\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:5\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:6\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:7\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:8\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:9\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:10\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:11\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:12\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:13\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:14\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:15\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:16\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:17\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:18\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:19\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:20\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "--\n",
      "시도:21\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "Game Clear\n"
     ]
    }
   ],
   "source": [
    "env = Bandit()\n",
    "agent = Agent()\n",
    "for t in range(1,51):\n",
    "    agent.act()\n",
    "    agent.reward = env.step(agent.action)\n",
    "    agent.save_experience()\n",
    "\n",
    "    print(\n",
    "        f\"시도:{t}\\t\"\n",
    "        f\"행동:{agent.action}\\t\"\n",
    "        f\"보상:{agent.reward}\\t\"\n",
    "        f\"최근20번보상평균:{np.mean(agent.rewards[-20:]):.4f}\\t\"\n",
    "    )\n",
    "    if t<20:\n",
    "        pass \n",
    "    elif t==20:\n",
    "        print(\"--\")\n",
    "    else: \n",
    "        if np.mean(agent.rewards[-20:]) > 9.5:\n",
    "            print(\"Game Clear\")\n",
    "            break    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7abefe-029f-4e8b-9837-bf94771a2071",
   "metadata": {},
   "source": [
    "## **D. 수정3: Agent 구현 (인공지능)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd680bb9-6608-4eef-8ae4-9453b20a6df1",
   "metadata": {},
   "source": [
    "`-` 지금까지 풀이의 한계\n",
    "- 사실 강화학습은 환경을 이해 -> 행동을 결정 과정에서 ->의 과정을 수식화 한 것\n",
    "- 그런데 지금까지는 환경을 파악하면 인간의 지능으로 코드를 수정했으므로 기계가 스스로 생각했다고 할 수 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9ab163-bc09-4831-9bec-67adc41397b0",
   "metadata": {},
   "source": [
    "`-` Agent가 데이터를 보고 스스로 학습할 수 있도록 설계 - 부제: `agent.learn()`을 설계하자"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c976883f-5ab2-40ed-88a7-40d999f5aefd",
   "metadata": {},
   "source": [
    "1. 데이터를 모아서 `q_table`을 만든다.\n",
    "2. `q_table`을 바탕으로 적절한 정책(=`policy`)를 설정한다.\n",
    "- $(\\frac{q_0}{q_0+q_1} , \\frac{q_1}{q_0+q_1})$으로 생각하면 될 것 같다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11ebb11-5d9e-4ff7-9021-9367784397eb",
   "metadata": {},
   "source": [
    "`-` `q_table`을 계산하는 코드 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "87d04427-6b93-4853-a9c2-62a4d2eded51",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.actions = [0, 1, 1,  0, 1,   0, 0] \n",
    "agent.rewards = [1, 9, 10, 1, 9.5, 1, 1.2] \n",
    "actions = np.array(agent.actions)\n",
    "rewards = np.array(agent.rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "42fd2c7f-992f-4981-9658-bdbb76448d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "q0 , q1 = np.mean(rewards[actions == 0]) , np.mean(rewards[actions == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "33611a1a-1341-4711-a6ad-0cf369adfa86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.05, 9.5 ])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table = np.array([q0,q1])\n",
    "q_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "137c5fb9-a06c-4e9b-8204-f487c8b3ebd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob = q_table / q_table.sum()\n",
    "agent.action = np.random.choice(action_space , p = prob)\n",
    "agent.action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad59399-72fc-4108-b24c-0b16f8bd0309",
   "metadata": {},
   "source": [
    "`-` 최종코드 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "11415594-70df-47b3-b2f6-5bedc18215bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self):\n",
    "        self.action_space = [0,1]\n",
    "        self.action = None \n",
    "        self.reward = None\n",
    "        self.actions = []\n",
    "        self.rewards = []\n",
    "        self.q_table = np.array([0.001,0.001])\n",
    "        self.n_experience = 0 \n",
    "    def act(self):\n",
    "        if self.n_experience <= 20:\n",
    "            self.action = np.random.choice(self.action_space)\n",
    "        else:\n",
    "            prob = q_table / q_table.sum()\n",
    "            self.action = np.random.choice(self.action_space , p=prob)\n",
    "    def save_experience(self):\n",
    "        self.actions.append(self.action)\n",
    "        self.rewards.append(self.reward)\n",
    "        self.n_experience = self.n_experience + 1 \n",
    "    def learn(self):\n",
    "        if self.n_experience < 20:\n",
    "            pass \n",
    "        else: \n",
    "            actions = np.array(self.actions)\n",
    "            rewards = np.array(self.rewards)      \n",
    "            q0,q1 = rewards[actions==0].mean(), rewards[actions==1].mean()\n",
    "            self.q_table = np.array([q0,q1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "365c68e1-d121-46c0-a5d4-ca935d05daf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시도:1\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:2\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:3\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:4\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:5\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:6\t행동:0\t보상:1\t최근20번보상평균:8.5000\t\n",
      "시도:7\t행동:1\t보상:10\t최근20번보상평균:8.7143\t\n",
      "시도:8\t행동:0\t보상:1\t최근20번보상평균:7.7500\t\n",
      "시도:9\t행동:0\t보상:1\t최근20번보상평균:7.0000\t\n",
      "시도:10\t행동:1\t보상:10\t최근20번보상평균:7.3000\t\n",
      "시도:11\t행동:0\t보상:1\t최근20번보상평균:6.7273\t\n",
      "시도:12\t행동:0\t보상:1\t최근20번보상평균:6.2500\t\n",
      "시도:13\t행동:0\t보상:1\t최근20번보상평균:5.8462\t\n",
      "시도:14\t행동:0\t보상:1\t최근20번보상평균:5.5000\t\n",
      "시도:15\t행동:0\t보상:1\t최근20번보상평균:5.2000\t\n",
      "시도:16\t행동:0\t보상:1\t최근20번보상평균:4.9375\t\n",
      "시도:17\t행동:1\t보상:10\t최근20번보상평균:5.2353\t\n",
      "시도:18\t행동:1\t보상:10\t최근20번보상평균:5.5000\t\n",
      "시도:19\t행동:0\t보상:1\t최근20번보상평균:5.2632\t\n",
      "시도:20\t행동:1\t보상:10\t최근20번보상평균:5.5000\t\n",
      "--\n",
      "시도:21\t행동:0\t보상:1\t최근20번보상평균:5.0500\t\n",
      "시도:22\t행동:1\t보상:10\t최근20번보상평균:5.0500\t\n",
      "시도:23\t행동:1\t보상:10\t최근20번보상평균:5.0500\t\n",
      "시도:24\t행동:1\t보상:10\t최근20번보상평균:5.0500\t\n",
      "시도:25\t행동:1\t보상:10\t최근20번보상평균:5.0500\t\n",
      "시도:26\t행동:1\t보상:10\t최근20번보상평균:5.5000\t\n",
      "시도:27\t행동:1\t보상:10\t최근20번보상평균:5.5000\t\n",
      "시도:28\t행동:1\t보상:10\t최근20번보상평균:5.9500\t\n",
      "시도:29\t행동:1\t보상:10\t최근20번보상평균:6.4000\t\n",
      "시도:30\t행동:1\t보상:10\t최근20번보상평균:6.4000\t\n",
      "시도:31\t행동:1\t보상:10\t최근20번보상평균:6.8500\t\n",
      "시도:32\t행동:1\t보상:10\t최근20번보상평균:7.3000\t\n",
      "시도:33\t행동:1\t보상:10\t최근20번보상평균:7.7500\t\n",
      "시도:34\t행동:1\t보상:10\t최근20번보상평균:8.2000\t\n",
      "시도:35\t행동:0\t보상:1\t최근20번보상평균:8.2000\t\n",
      "시도:36\t행동:1\t보상:10\t최근20번보상평균:8.6500\t\n",
      "시도:37\t행동:1\t보상:10\t최근20번보상평균:8.6500\t\n",
      "시도:38\t행동:1\t보상:10\t최근20번보상평균:8.6500\t\n",
      "시도:39\t행동:0\t보상:1\t최근20번보상평균:8.6500\t\n",
      "시도:40\t행동:1\t보상:10\t최근20번보상평균:8.6500\t\n",
      "시도:41\t행동:1\t보상:10\t최근20번보상평균:9.1000\t\n",
      "시도:42\t행동:1\t보상:10\t최근20번보상평균:9.1000\t\n",
      "시도:43\t행동:1\t보상:10\t최근20번보상평균:9.1000\t\n",
      "시도:44\t행동:1\t보상:10\t최근20번보상평균:9.1000\t\n",
      "시도:45\t행동:1\t보상:10\t최근20번보상평균:9.1000\t\n",
      "시도:46\t행동:1\t보상:10\t최근20번보상평균:9.1000\t\n",
      "시도:47\t행동:1\t보상:10\t최근20번보상평균:9.1000\t\n",
      "시도:48\t행동:1\t보상:10\t최근20번보상평균:9.1000\t\n",
      "시도:49\t행동:0\t보상:1\t최근20번보상평균:8.6500\t\n",
      "시도:50\t행동:1\t보상:10\t최근20번보상평균:8.6500\t\n"
     ]
    }
   ],
   "source": [
    "env = Bandit()\n",
    "agent = Agent()\n",
    "for t in range(1,51):\n",
    "    # step1: 행동\n",
    "    agent.act()\n",
    "    # step2: 보상\n",
    "    agent.reward = env.step(agent.action)\n",
    "    # step3: 저장 & 학습\n",
    "    agent.save_experience()\n",
    "    agent.learn()    \n",
    "    #--#\n",
    "    print(\n",
    "        f\"시도:{t}\\t\"\n",
    "        f\"행동:{agent.action}\\t\"\n",
    "        f\"보상:{agent.reward}\\t\"\n",
    "        f\"최근20번보상평균:{np.mean(agent.rewards[-20:]):.4f}\\t\"\n",
    "    )\n",
    "    if t<20:\n",
    "        pass \n",
    "    elif t==20:\n",
    "        print(\"--\")\n",
    "    else: \n",
    "        if np.mean(agent.rewards[-20:]) > 9.5:\n",
    "            print(\"Game Clear\")\n",
    "            break    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
